

============================== 2022-07-27 21:07:37.125502 | c753ce90-4226-408f-8e2c-36a54a109654 ==============================
[0m21:07:37.125612 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:07:37.133440 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:07:37.134558 [debug] [MainThread]: Tracking: tracking
[0m21:07:37.321875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6b694f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6b695e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6b695b0>]}
[0m21:07:37.460974 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:07:37.462984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6b7e760>]}
[0m21:07:37.527585 [debug] [MainThread]: Parsing macros/relations.sql
[0m21:07:37.543261 [debug] [MainThread]: Parsing macros/adapters.sql
[0m21:07:37.695602 [debug] [MainThread]: Parsing macros/catalog.sql
[0m21:07:37.704743 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
[0m21:07:37.712354 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m21:07:37.714921 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m21:07:37.720765 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m21:07:37.723980 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m21:07:37.729198 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m21:07:37.755901 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m21:07:37.762606 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m21:07:37.773383 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m21:07:37.791589 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m21:07:37.799439 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m21:07:37.853495 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m21:07:38.016788 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m21:07:38.118960 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m21:07:38.207479 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m21:07:38.381032 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m21:07:38.459703 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m21:07:38.503415 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m21:07:38.643316 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m21:07:38.747925 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m21:07:38.754874 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m21:07:38.769674 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m21:07:38.815611 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m21:07:38.831205 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m21:07:38.841413 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m21:07:38.905499 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m21:07:38.950159 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m21:07:38.982008 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m21:07:39.065959 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m21:07:39.109511 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m21:07:39.118655 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m21:07:39.134203 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m21:07:39.155926 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m21:07:39.179953 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m21:07:39.302678 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m21:07:39.370175 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m21:07:39.430497 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m21:07:39.473669 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m21:07:39.598146 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m21:07:39.622897 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m21:07:39.635905 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m21:07:39.657251 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m21:07:39.665171 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m21:07:39.676900 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m21:07:39.688048 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m21:07:39.695171 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m21:07:39.712345 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m21:07:39.726774 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m21:07:39.745963 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m21:07:39.781097 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m21:07:39.785554 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m21:07:39.811219 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m21:07:39.817874 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m21:07:39.832006 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m21:07:39.846837 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m21:07:39.937438 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m21:07:39.953695 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m21:07:39.973536 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m21:07:39.989986 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m21:07:40.020142 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m21:07:40.047142 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m21:07:40.065701 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m21:07:40.074993 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m21:07:40.140629 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m21:07:40.249404 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m21:07:40.269520 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m21:07:40.298706 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m21:07:40.316054 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m21:07:42.789841 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m21:07:42.945704 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m21:07:42.972925 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/dim_types.sql
[0m21:07:43.001028 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_summary.sql
[0m21:07:43.017967 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_trajectory.sql
[0m21:07:43.488917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6a9eee0>]}
[0m21:07:43.516397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6619a30>]}
[0m21:07:43.517794 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:07:43.519899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6a26fd0>]}
[0m21:07:43.526597 [info ] [MainThread]: 
[0m21:07:43.529093 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:07:43.534439 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:07:43.596812 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:07:43.597741 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:07:43.598476 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:07:43.620927 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.02 seconds
[0m21:07:43.626854 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:07:43.649010 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:07:43.711653 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:07:43.712799 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:07:43.713697 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:07:43.726782 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
[0m21:07:43.729289 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:07:43.730189 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:07:43.757106 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.03 seconds
[0m21:07:43.765747 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:07:43.772362 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:07:43.790453 [debug] [MainThread]: Using postgres connection "master"
[0m21:07:43.791379 [debug] [MainThread]: On master: BEGIN
[0m21:07:43.797666 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:07:43.813454 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:07:43.815368 [debug] [MainThread]: Using postgres connection "master"
[0m21:07:43.816748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:07:43.853589 [debug] [MainThread]: SQL status: SELECT 1 in 0.03 seconds
[0m21:07:43.867461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6a9ed00>]}
[0m21:07:43.872833 [debug] [MainThread]: On master: ROLLBACK
[0m21:07:43.874456 [debug] [MainThread]: Using postgres connection "master"
[0m21:07:43.875381 [debug] [MainThread]: On master: BEGIN
[0m21:07:43.884905 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:07:43.886641 [debug] [MainThread]: On master: COMMIT
[0m21:07:43.892079 [debug] [MainThread]: Using postgres connection "master"
[0m21:07:43.893849 [debug] [MainThread]: On master: COMMIT
[0m21:07:43.899499 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:07:43.906314 [debug] [MainThread]: On master: Close
[0m21:07:43.917659 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:07:43.919299 [info ] [MainThread]: 
[0m21:07:43.968515 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:07:43.969906 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:07:43.974976 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:07:43.975920 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:07:43.976853 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:07:43.989039 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:07:43.990884 [debug] [Thread-1  ]: finished collecting timing info
[0m21:07:43.991899 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:07:44.360302 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:07:44.366988 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:07:44.367928 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:07:44.368834 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:07:44.383186 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
[0m21:07:44.384649 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:07:44.385768 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "warehouse"."warehouse"."source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:07:44.408225 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "warehouse.source" does not exist
LINE 8:     select * from "warehouse"."warehouse"."source"
                          ^

[0m21:07:44.409251 [debug] [Thread-1  ]: On model.dbt_.dim_types: ROLLBACK
[0m21:07:44.411395 [debug] [Thread-1  ]: finished collecting timing info
[0m21:07:44.412458 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:07:44.414413 [debug] [Thread-1  ]: Database Error in model dim_types (models/traffic_models/dim_types.sql)
  relation "warehouse.source" does not exist
  LINE 8:     select * from "warehouse"."warehouse"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:07:44.415711 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff44ce910>]}
[0m21:07:44.423606 [error] [Thread-1  ]: 1 of 5 ERROR creating table model warehouse.dim_types .......................... [[31mERROR[0m in 0.44s]
[0m21:07:44.434923 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:07:44.436070 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:07:44.444036 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:07:44.450951 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:44.451891 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:07:44.461019 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:07:44.486059 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:07:44.487577 [debug] [Thread-1  ]: finished collecting timing info
[0m21:07:44.497355 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:07:44.543609 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:07:44.561434 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:44.566882 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:07:44.567656 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:07:44.587775 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:07:44.588842 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:44.589588 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:07:44.595609 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.0 seconds
[0m21:07:44.679904 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:44.692861 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:07:44.695142 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:07:44.762432 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:44.763329 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:07:44.781549 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.02 seconds
[0m21:07:45.211528 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:07:45.218537 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:45.228422 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:07:45.245909 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:07:45.280322 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:07:45.281410 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:07:45.302072 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.02 seconds
[0m21:07:45.305997 [debug] [Thread-1  ]: finished collecting timing info
[0m21:07:45.307053 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:07:45.320343 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff65928b0>]}
[0m21:07:45.321984 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.87s]
[0m21:07:45.336723 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:07:45.337996 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:07:45.345320 [info ] [Thread-1  ]: 3 of 5 SKIP relation warehouse.fct_summary ..................................... [[33mSKIP[0m]
[0m21:07:45.353047 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:07:45.358689 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:07:45.372331 [info ] [Thread-1  ]: 4 of 5 SKIP relation warehouse.fct_trajectory .................................. [[33mSKIP[0m]
[0m21:07:45.375525 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:07:45.380528 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:07:45.385990 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:07:45.390165 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:07:45.391161 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:07:45.397286 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:07:45.438242 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:07:45.445511 [debug] [Thread-1  ]: finished collecting timing info
[0m21:07:45.446640 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:07:45.671627 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:07:45.677851 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:07:45.678848 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:07:45.681322 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:07:45.696420 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:07:45.697384 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:07:45.698175 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:07:45.706028 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m21:07:45.718274 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:07:45.719178 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:07:45.731888 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:07:45.755824 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:07:45.756807 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:07:45.757658 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:07:45.778728 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:07:45.799449 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:07:45.800625 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:07:45.809268 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m21:07:45.818271 [debug] [Thread-1  ]: finished collecting timing info
[0m21:07:45.824318 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:07:45.829411 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c753ce90-4226-408f-8e2c-36a54a109654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff44ced60>]}
[0m21:07:45.836666 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.44s]
[0m21:07:45.841517 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:07:45.863284 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:07:45.864955 [debug] [MainThread]: Using postgres connection "master"
[0m21:07:45.866194 [debug] [MainThread]: On master: BEGIN
[0m21:07:45.867069 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:07:45.882766 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:07:45.884097 [debug] [MainThread]: On master: COMMIT
[0m21:07:45.888119 [debug] [MainThread]: Using postgres connection "master"
[0m21:07:45.892204 [debug] [MainThread]: On master: COMMIT
[0m21:07:45.901053 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:07:45.908327 [debug] [MainThread]: On master: Close
[0m21:07:45.916110 [info ] [MainThread]: 
[0m21:07:45.917876 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 2.39 seconds (2.39s).
[0m21:07:45.924605 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:07:45.931959 [debug] [MainThread]: Connection 'list_warehouse' was properly closed.
[0m21:07:45.932887 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:07:46.022111 [info ] [MainThread]: 
[0m21:07:46.026239 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:07:46.053084 [info ] [MainThread]: 
[0m21:07:46.059244 [error] [MainThread]: [33mDatabase Error in model dim_types (models/traffic_models/dim_types.sql)[0m
[0m21:07:46.069292 [error] [MainThread]:   relation "warehouse.source" does not exist
[0m21:07:46.078576 [error] [MainThread]:   LINE 8:     select * from "warehouse"."warehouse"."source"
[0m21:07:46.086814 [error] [MainThread]:                             ^
[0m21:07:46.090253 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:07:46.102003 [info ] [MainThread]: 
[0m21:07:46.145309 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 TOTAL=5
[0m21:07:46.162754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff658bf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff6b7e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff44ced60>]}


============================== 2022-07-27 21:12:17.533748 | c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c ==============================
[0m21:12:17.533882 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:12:17.552806 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:12:17.560519 [debug] [MainThread]: Tracking: tracking
[0m21:12:17.801662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016cb0520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016cb0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016cb05e0>]}
[0m21:12:18.011181 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m21:12:18.013120 [debug] [MainThread]: Partial parsing: added file: dbt_://models/traffic_models/schema.yml
[0m21:12:18.024887 [debug] [MainThread]: Partial parsing: deleted source source.dbt_.traffic_source.source
[0m21:12:18.095307 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_summary.sql
[0m21:12:18.157689 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_trajectory.sql
[0m21:12:18.198725 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/dim_types.sql
[0m21:12:18.334661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016722eb0>]}
[0m21:12:18.366246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016c29b50>]}
[0m21:12:18.367794 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:12:18.370384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016b9a100>]}
[0m21:12:18.378231 [info ] [MainThread]: 
[0m21:12:18.382145 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:12:18.389848 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:12:18.445581 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:12:18.446700 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:12:18.448366 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:12:18.474407 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.03 seconds
[0m21:12:18.479491 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:12:18.503716 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:12:18.609026 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:12:18.616062 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:12:18.628125 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:12:18.670636 [debug] [ThreadPool]: SQL status: BEGIN in 0.04 seconds
[0m21:12:18.671591 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:12:18.672660 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:12:18.683510 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.01 seconds
[0m21:12:18.706182 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:12:18.713017 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:12:18.743676 [debug] [MainThread]: Using postgres connection "master"
[0m21:12:18.750703 [debug] [MainThread]: On master: BEGIN
[0m21:12:18.751450 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:12:18.782191 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
[0m21:12:18.785241 [debug] [MainThread]: Using postgres connection "master"
[0m21:12:18.789834 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:12:18.835736 [debug] [MainThread]: SQL status: SELECT 1 in 0.04 seconds
[0m21:12:18.840005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016b67e80>]}
[0m21:12:18.841331 [debug] [MainThread]: On master: ROLLBACK
[0m21:12:18.850754 [debug] [MainThread]: Using postgres connection "master"
[0m21:12:18.851702 [debug] [MainThread]: On master: BEGIN
[0m21:12:18.867628 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
[0m21:12:18.869156 [debug] [MainThread]: On master: COMMIT
[0m21:12:18.874725 [debug] [MainThread]: Using postgres connection "master"
[0m21:12:18.883465 [debug] [MainThread]: On master: COMMIT
[0m21:12:18.891721 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
[0m21:12:18.892796 [debug] [MainThread]: On master: Close
[0m21:12:18.894788 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:12:18.898149 [info ] [MainThread]: 
[0m21:12:18.950762 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:12:18.952075 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:12:18.955627 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:12:18.956668 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:12:18.957540 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:12:18.985039 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:12:18.990134 [debug] [Thread-1  ]: finished collecting timing info
[0m21:12:18.992315 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:12:19.273980 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:12:19.275996 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:12:19.277196 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:12:19.278081 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:12:19.295095 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:12:19.296055 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:12:19.297103 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "warehouse"."warehouse"."source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:12:19.300401 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "warehouse.source" does not exist
LINE 8:     select * from "warehouse"."warehouse"."source"
                          ^

[0m21:12:19.302023 [debug] [Thread-1  ]: On model.dbt_.dim_types: ROLLBACK
[0m21:12:19.309457 [debug] [Thread-1  ]: finished collecting timing info
[0m21:12:19.310959 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:12:19.317565 [debug] [Thread-1  ]: Database Error in model dim_types (models/traffic_models/dim_types.sql)
  relation "warehouse.source" does not exist
  LINE 8:     select * from "warehouse"."warehouse"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:12:19.320007 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff014634490>]}
[0m21:12:19.324315 [error] [Thread-1  ]: 1 of 5 ERROR creating table model warehouse.dim_types .......................... [[31mERROR[0m in 0.37s]
[0m21:12:19.329999 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:12:19.334064 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:12:19.337859 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:12:19.346507 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.350385 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:12:19.351629 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:12:19.387827 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:12:19.397331 [debug] [Thread-1  ]: finished collecting timing info
[0m21:12:19.398294 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:12:19.422842 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:12:19.425687 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.426606 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:12:19.427310 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:12:19.445859 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:12:19.449003 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.451479 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:12:19.458600 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.01 seconds
[0m21:12:19.515315 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.516474 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:12:19.519163 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:12:19.545612 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.550819 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:12:19.554039 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:12:19.692905 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:12:19.693847 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.694570 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:12:19.722038 [debug] [Thread-1  ]: SQL status: COMMIT in 0.03 seconds
[0m21:12:19.785405 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:12:19.786338 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:12:19.811969 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.02 seconds
[0m21:12:19.815776 [debug] [Thread-1  ]: finished collecting timing info
[0m21:12:19.816862 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:12:19.818934 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0166c47f0>]}
[0m21:12:19.820532 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.47s]
[0m21:12:19.831942 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:12:19.835264 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:12:19.839605 [info ] [Thread-1  ]: 3 of 5 SKIP relation warehouse.fct_summary ..................................... [[33mSKIP[0m]
[0m21:12:19.842758 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:12:19.844260 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:12:19.845574 [info ] [Thread-1  ]: 4 of 5 SKIP relation warehouse.fct_trajectory .................................. [[33mSKIP[0m]
[0m21:12:19.847975 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:12:19.849860 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:12:19.851389 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:12:19.854732 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:12:19.856040 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:12:19.858128 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:12:19.867247 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:12:19.869269 [debug] [Thread-1  ]: finished collecting timing info
[0m21:12:19.870438 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:12:20.142009 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:12:20.143641 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:12:20.144584 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:12:20.152237 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:12:20.171412 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:12:20.174068 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:12:20.177398 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:12:20.185599 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.01 seconds
[0m21:12:20.195739 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:12:20.196759 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:12:20.199554 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:12:20.206233 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:12:20.207408 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:12:20.208190 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:12:20.243881 [debug] [Thread-1  ]: SQL status: COMMIT in 0.03 seconds
[0m21:12:20.251177 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:12:20.252449 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:12:20.255517 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m21:12:20.264495 [debug] [Thread-1  ]: finished collecting timing info
[0m21:12:20.265488 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:12:20.275699 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1d32072-0ca2-44c9-8e1a-4ef7bbd1fa8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff01565c490>]}
[0m21:12:20.277235 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.42s]
[0m21:12:20.285613 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:12:20.290628 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:12:20.292598 [debug] [MainThread]: Using postgres connection "master"
[0m21:12:20.293585 [debug] [MainThread]: On master: BEGIN
[0m21:12:20.294376 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:12:20.353270 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
[0m21:12:20.354829 [debug] [MainThread]: On master: COMMIT
[0m21:12:20.358535 [debug] [MainThread]: Using postgres connection "master"
[0m21:12:20.359580 [debug] [MainThread]: On master: COMMIT
[0m21:12:20.361368 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:12:20.362347 [debug] [MainThread]: On master: Close
[0m21:12:20.371104 [info ] [MainThread]: 
[0m21:12:20.374203 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 1.99 seconds (1.99s).
[0m21:12:20.377134 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:12:20.378082 [debug] [MainThread]: Connection 'list_warehouse' was properly closed.
[0m21:12:20.382686 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:12:20.413589 [info ] [MainThread]: 
[0m21:12:20.416482 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:12:20.419449 [info ] [MainThread]: 
[0m21:12:20.422847 [error] [MainThread]: [33mDatabase Error in model dim_types (models/traffic_models/dim_types.sql)[0m
[0m21:12:20.426274 [error] [MainThread]:   relation "warehouse.source" does not exist
[0m21:12:20.429625 [error] [MainThread]:   LINE 8:     select * from "warehouse"."warehouse"."source"
[0m21:12:20.432445 [error] [MainThread]:                             ^
[0m21:12:20.434275 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:12:20.438661 [info ] [MainThread]: 
[0m21:12:20.442458 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 TOTAL=5
[0m21:12:20.445594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff016b79dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff01458cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff01458c610>]}


============================== 2022-07-27 21:13:01.384874 | 660e18c5-7fc5-4858-8f8b-9220ee6122f7 ==============================
[0m21:13:01.385003 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:13:01.393056 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:13:01.396114 [debug] [MainThread]: Tracking: tracking
[0m21:13:01.624382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c09c684c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c09c685b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c09c68580>]}
[0m21:13:02.015334 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:13:02.023880 [debug] [MainThread]: Partial parsing: deleted source source.dbt_.traffic_source.source
[0m21:13:02.031148 [debug] [MainThread]: Partial parsing: update schema file: dbt_://models/traffic_models/schema.yml
[0m21:13:02.172837 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_summary.sql
[0m21:13:02.281852 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_trajectory.sql
[0m21:13:02.294446 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/dim_types.sql
[0m21:13:02.445020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c096dbd60>]}
[0m21:13:02.505326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c096a87f0>]}
[0m21:13:02.506716 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:13:02.516754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c09b4cf70>]}
[0m21:13:02.541888 [info ] [MainThread]: 
[0m21:13:02.548473 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:13:02.585475 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:13:02.752009 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:13:02.754800 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:13:02.757765 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:02.792066 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.03 seconds
[0m21:13:02.798437 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:13:02.810291 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:13:02.869363 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:13:02.870266 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:13:02.872469 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:02.896735 [debug] [ThreadPool]: SQL status: BEGIN in 0.02 seconds
[0m21:13:02.897687 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:13:02.900290 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:13:02.910053 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.01 seconds
[0m21:13:02.914147 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:13:02.916526 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:13:02.943611 [debug] [MainThread]: Using postgres connection "master"
[0m21:13:02.948037 [debug] [MainThread]: On master: BEGIN
[0m21:13:02.950610 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:13:02.972921 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:13:02.973868 [debug] [MainThread]: Using postgres connection "master"
[0m21:13:02.974605 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:13:03.025240 [debug] [MainThread]: SQL status: SELECT 1 in 0.05 seconds
[0m21:13:03.030443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c09aec9a0>]}
[0m21:13:03.031737 [debug] [MainThread]: On master: ROLLBACK
[0m21:13:03.037414 [debug] [MainThread]: Using postgres connection "master"
[0m21:13:03.039261 [debug] [MainThread]: On master: BEGIN
[0m21:13:03.050257 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:13:03.053128 [debug] [MainThread]: On master: COMMIT
[0m21:13:03.054002 [debug] [MainThread]: Using postgres connection "master"
[0m21:13:03.054707 [debug] [MainThread]: On master: COMMIT
[0m21:13:03.063499 [debug] [MainThread]: SQL status: COMMIT in 0.01 seconds
[0m21:13:03.065957 [debug] [MainThread]: On master: Close
[0m21:13:03.075030 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:13:03.096822 [info ] [MainThread]: 
[0m21:13:03.130486 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:13:03.131780 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:13:03.137167 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:13:03.138371 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:13:03.139254 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:13:03.151564 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:13:03.153201 [debug] [Thread-1  ]: finished collecting timing info
[0m21:13:03.154799 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:13:03.514738 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:13:03.519432 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:13:03.523092 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:13:03.524120 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:13:03.542654 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:13:03.545078 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:13:03.546280 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "warehouse"."traffic_source"."source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:13:03.549749 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "traffic_source.source" does not exist
LINE 8:     select * from "warehouse"."traffic_source"."source"
                          ^

[0m21:13:03.557473 [debug] [Thread-1  ]: On model.dbt_.dim_types: ROLLBACK
[0m21:13:03.562969 [debug] [Thread-1  ]: finished collecting timing info
[0m21:13:03.564125 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:13:03.566021 [debug] [Thread-1  ]: Database Error in model dim_types (models/traffic_models/dim_types.sql)
  relation "traffic_source.source" does not exist
  LINE 8:     select * from "warehouse"."traffic_source"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:13:03.578873 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c085e2e20>]}
[0m21:13:03.585107 [error] [Thread-1  ]: 1 of 5 ERROR creating table model warehouse.dim_types .......................... [[31mERROR[0m in 0.44s]
[0m21:13:03.596421 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:13:03.601889 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:13:03.605585 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:13:03.613610 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:03.624350 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:13:03.626319 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:13:03.651626 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:13:03.658885 [debug] [Thread-1  ]: finished collecting timing info
[0m21:13:03.661739 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:13:03.703769 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:13:03.714299 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:03.717816 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:13:03.718937 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:13:03.751296 [debug] [Thread-1  ]: SQL status: BEGIN in 0.03 seconds
[0m21:13:03.753677 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:03.755123 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:13:03.761567 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.01 seconds
[0m21:13:03.817946 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:03.824443 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:13:03.826729 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:13:03.851813 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:03.855471 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:13:03.861909 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:13:04.242211 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:13:04.243146 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:04.264584 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:13:04.283383 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:13:04.335963 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:13:04.337606 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:13:04.361378 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.02 seconds
[0m21:13:04.365309 [debug] [Thread-1  ]: finished collecting timing info
[0m21:13:04.366301 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:13:04.373799 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c085e2700>]}
[0m21:13:04.375331 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.76s]
[0m21:13:04.397113 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:13:04.400971 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:13:04.402912 [info ] [Thread-1  ]: 3 of 5 SKIP relation warehouse.fct_summary ..................................... [[33mSKIP[0m]
[0m21:13:04.417865 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:13:04.419340 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:13:04.422628 [info ] [Thread-1  ]: 4 of 5 SKIP relation warehouse.fct_trajectory .................................. [[33mSKIP[0m]
[0m21:13:04.462873 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:13:04.464875 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:13:04.467561 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:13:04.476379 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:13:04.478651 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:13:04.480003 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:13:04.490141 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:13:04.491966 [debug] [Thread-1  ]: finished collecting timing info
[0m21:13:04.493972 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:13:04.661896 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:13:04.671454 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:13:04.672965 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:13:04.674679 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:13:04.698317 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:13:04.702685 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:13:04.709071 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:13:04.717738 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.01 seconds
[0m21:13:04.729245 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:13:04.730834 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:13:04.733323 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:13:04.740991 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:13:04.742072 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:13:04.745391 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:13:04.760404 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
[0m21:13:04.775682 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:13:04.788632 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:13:04.791030 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m21:13:04.796056 [debug] [Thread-1  ]: finished collecting timing info
[0m21:13:04.797328 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:13:04.808546 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '660e18c5-7fc5-4858-8f8b-9220ee6122f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c086153d0>]}
[0m21:13:04.813636 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.33s]
[0m21:13:04.823188 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:13:04.829338 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:13:04.830881 [debug] [MainThread]: Using postgres connection "master"
[0m21:13:04.832424 [debug] [MainThread]: On master: BEGIN
[0m21:13:04.834033 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:13:04.878083 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
[0m21:13:04.880643 [debug] [MainThread]: On master: COMMIT
[0m21:13:04.881419 [debug] [MainThread]: Using postgres connection "master"
[0m21:13:04.882110 [debug] [MainThread]: On master: COMMIT
[0m21:13:04.884557 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:13:04.885928 [debug] [MainThread]: On master: Close
[0m21:13:04.893426 [info ] [MainThread]: 
[0m21:13:04.903784 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 2.35 seconds (2.35s).
[0m21:13:04.909047 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:13:04.909864 [debug] [MainThread]: Connection 'list_warehouse' was properly closed.
[0m21:13:04.912811 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:13:05.008576 [info ] [MainThread]: 
[0m21:13:05.010688 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:13:05.020793 [info ] [MainThread]: 
[0m21:13:05.023205 [error] [MainThread]: [33mDatabase Error in model dim_types (models/traffic_models/dim_types.sql)[0m
[0m21:13:05.027019 [error] [MainThread]:   relation "traffic_source.source" does not exist
[0m21:13:05.032420 [error] [MainThread]:   LINE 8:     select * from "warehouse"."traffic_source"."source"
[0m21:13:05.043423 [error] [MainThread]:                             ^
[0m21:13:05.045035 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:13:05.057606 [info ] [MainThread]: 
[0m21:13:05.066359 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 TOTAL=5
[0m21:13:05.074371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c09b30d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c08546d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c08546a90>]}


============================== 2022-07-27 21:17:00.008397 | 3a2f7873-0cba-4436-946e-fc7cedcbf49b ==============================
[0m21:17:00.008536 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:17:00.018206 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:17:00.024426 [debug] [MainThread]: Tracking: tracking
[0m21:17:00.247309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05ee4d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05ee4d6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05ee4d670>]}
[0m21:17:00.587397 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:17:00.596495 [debug] [MainThread]: Partial parsing: deleted source source.dbt_.traffic_source.source
[0m21:17:00.599331 [debug] [MainThread]: Partial parsing: update schema file: dbt_://models/traffic_models/schema.yml
[0m21:17:00.755666 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_summary.sql
[0m21:17:00.815128 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_trajectory.sql
[0m21:17:00.828140 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/dim_types.sql
[0m21:17:00.937691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05e8bf070>]}
[0m21:17:00.967682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05e88d850>]}
[0m21:17:00.969426 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:17:00.971219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05ed360a0>]}
[0m21:17:00.978013 [info ] [MainThread]: 
[0m21:17:00.980691 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:17:00.985404 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:17:01.026280 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:17:01.032413 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:17:01.033537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:17:01.049066 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.02 seconds
[0m21:17:01.055088 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:17:01.086831 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:17:01.185282 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:17:01.194821 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:17:01.196286 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:17:01.225283 [debug] [ThreadPool]: SQL status: BEGIN in 0.03 seconds
[0m21:17:01.228869 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:17:01.237260 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:17:01.249532 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.01 seconds
[0m21:17:01.254517 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:17:01.261359 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:17:01.312018 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:01.321087 [debug] [MainThread]: On master: BEGIN
[0m21:17:01.321982 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:17:01.334752 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
[0m21:17:01.336263 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:01.337186 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:17:01.364446 [debug] [MainThread]: SQL status: SELECT 1 in 0.03 seconds
[0m21:17:01.368651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05e8690a0>]}
[0m21:17:01.370146 [debug] [MainThread]: On master: ROLLBACK
[0m21:17:01.372203 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:01.373271 [debug] [MainThread]: On master: BEGIN
[0m21:17:01.376546 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:17:01.377761 [debug] [MainThread]: On master: COMMIT
[0m21:17:01.378705 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:01.380232 [debug] [MainThread]: On master: COMMIT
[0m21:17:01.381810 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:17:01.382937 [debug] [MainThread]: On master: Close
[0m21:17:01.390276 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:17:01.392066 [info ] [MainThread]: 
[0m21:17:01.403220 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:17:01.404657 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:17:01.406865 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:17:01.407794 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:17:01.409066 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:17:01.419667 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:17:01.421585 [debug] [Thread-1  ]: finished collecting timing info
[0m21:17:01.422766 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:17:01.671993 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:17:01.685161 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:17:01.686920 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:17:01.687994 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:17:01.717183 [debug] [Thread-1  ]: SQL status: BEGIN in 0.03 seconds
[0m21:17:01.718177 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:17:01.718914 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "warehouse"."traffic_source"."source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:17:01.722669 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "traffic_source.source" does not exist
LINE 8:     select * from "warehouse"."traffic_source"."source"
                          ^

[0m21:17:01.732861 [debug] [Thread-1  ]: On model.dbt_.dim_types: ROLLBACK
[0m21:17:01.736088 [debug] [Thread-1  ]: finished collecting timing info
[0m21:17:01.741005 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:17:01.752682 [debug] [Thread-1  ]: Database Error in model dim_types (models/traffic_models/dim_types.sql)
  relation "traffic_source.source" does not exist
  LINE 8:     select * from "warehouse"."traffic_source"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:17:01.754272 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05c7cea60>]}
[0m21:17:01.755990 [error] [Thread-1  ]: 1 of 5 ERROR creating table model warehouse.dim_types .......................... [[31mERROR[0m in 0.35s]
[0m21:17:01.761698 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:17:01.766361 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:17:01.768418 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:17:01.781411 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:01.790345 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:17:01.792379 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:17:01.817851 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:17:01.826657 [debug] [Thread-1  ]: finished collecting timing info
[0m21:17:01.829229 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:17:01.906227 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:17:01.913875 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:01.916372 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:17:01.920631 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:17:01.935603 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
[0m21:17:01.941941 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:01.943064 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:17:01.948986 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.0 seconds
[0m21:17:01.999530 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:02.005161 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:17:02.009045 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:17:02.025972 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:02.029899 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:17:02.033705 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:17:02.223148 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:17:02.227761 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:02.230009 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:17:02.242347 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
[0m21:17:02.310678 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:17:02.318105 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:17:02.354086 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.03 seconds
[0m21:17:02.358659 [debug] [Thread-1  ]: finished collecting timing info
[0m21:17:02.368395 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:17:02.387436 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05e847eb0>]}
[0m21:17:02.389277 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.61s]
[0m21:17:02.391936 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:17:02.396518 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:17:02.398156 [info ] [Thread-1  ]: 3 of 5 SKIP relation warehouse.fct_summary ..................................... [[33mSKIP[0m]
[0m21:17:02.411660 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:17:02.413293 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:17:02.414595 [info ] [Thread-1  ]: 4 of 5 SKIP relation warehouse.fct_trajectory .................................. [[33mSKIP[0m]
[0m21:17:02.416821 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:17:02.420248 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:17:02.424049 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:17:02.429488 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:17:02.435687 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:17:02.439640 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:17:02.459166 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:17:02.462998 [debug] [Thread-1  ]: finished collecting timing info
[0m21:17:02.478556 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:17:02.705778 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:17:02.712326 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:17:02.714319 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:17:02.716292 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:17:02.731402 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:17:02.733570 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:17:02.734934 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:17:02.743291 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.01 seconds
[0m21:17:02.759750 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:17:02.761245 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:17:02.763445 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:17:02.770916 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:17:02.771995 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:17:02.772937 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:17:02.808832 [debug] [Thread-1  ]: SQL status: COMMIT in 0.04 seconds
[0m21:17:02.818637 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:17:02.819724 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:17:02.823075 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m21:17:02.832060 [debug] [Thread-1  ]: finished collecting timing info
[0m21:17:02.836100 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:17:02.848975 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a2f7873-0cba-4436-946e-fc7cedcbf49b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05d7fa520>]}
[0m21:17:02.850664 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.42s]
[0m21:17:02.853819 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:17:02.867109 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:17:02.868352 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:02.869331 [debug] [MainThread]: On master: BEGIN
[0m21:17:02.870174 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:17:02.881520 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
[0m21:17:02.883508 [debug] [MainThread]: On master: COMMIT
[0m21:17:02.884720 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:02.885612 [debug] [MainThread]: On master: COMMIT
[0m21:17:02.887128 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:17:02.888274 [debug] [MainThread]: On master: Close
[0m21:17:02.897980 [info ] [MainThread]: 
[0m21:17:02.899759 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 1.92 seconds (1.92s).
[0m21:17:02.903333 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:17:02.906338 [debug] [MainThread]: Connection 'list_warehouse' was properly closed.
[0m21:17:02.908451 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:17:02.967193 [info ] [MainThread]: 
[0m21:17:02.973246 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:17:02.975025 [info ] [MainThread]: 
[0m21:17:02.976606 [error] [MainThread]: [33mDatabase Error in model dim_types (models/traffic_models/dim_types.sql)[0m
[0m21:17:02.980883 [error] [MainThread]:   relation "traffic_source.source" does not exist
[0m21:17:02.984560 [error] [MainThread]:   LINE 8:     select * from "warehouse"."traffic_source"."source"
[0m21:17:02.993170 [error] [MainThread]:                             ^
[0m21:17:02.994718 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:17:02.996241 [info ] [MainThread]: 
[0m21:17:02.997768 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 TOTAL=5
[0m21:17:02.999515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05ed15e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05c72e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb05c72e9a0>]}


============================== 2022-07-27 21:18:08.486201 | a62dc8d8-f3fd-46a7-b2c1-e2759cd22814 ==============================
[0m21:18:08.486321 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:18:08.512519 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:18:08.514710 [debug] [MainThread]: Tracking: tracking
[0m21:18:08.749342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa120460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa120550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa120520>]}
[0m21:18:09.147596 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:18:09.149689 [debug] [MainThread]: Partial parsing: updated file: dbt_://models/traffic_models/dim_types.sql
[0m21:18:09.217613 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/dim_types.sql
[0m21:18:09.357150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3f9fc9130>]}
[0m21:18:09.385499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa09a8e0>]}
[0m21:18:09.387200 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:18:09.389032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3f9fc8f10>]}
[0m21:18:09.404600 [info ] [MainThread]: 
[0m21:18:09.417965 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:18:09.429240 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:18:09.495026 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:18:09.496140 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:18:09.497091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:09.515008 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.02 seconds
[0m21:18:09.529788 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:18:09.546577 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:18:09.651523 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:18:09.652495 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:18:09.656777 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:09.671846 [debug] [ThreadPool]: SQL status: BEGIN in 0.02 seconds
[0m21:18:09.675374 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:18:09.676125 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:18:09.688185 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.01 seconds
[0m21:18:09.694025 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:18:09.695650 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:18:09.742603 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:09.745577 [debug] [MainThread]: On master: BEGIN
[0m21:18:09.749878 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:18:09.806291 [debug] [MainThread]: SQL status: BEGIN in 0.06 seconds
[0m21:18:09.807226 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:09.807925 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:18:09.841271 [debug] [MainThread]: SQL status: SELECT 1 in 0.03 seconds
[0m21:18:09.845202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa137af0>]}
[0m21:18:09.847659 [debug] [MainThread]: On master: ROLLBACK
[0m21:18:09.849417 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:09.850315 [debug] [MainThread]: On master: BEGIN
[0m21:18:09.853225 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:18:09.854222 [debug] [MainThread]: On master: COMMIT
[0m21:18:09.855413 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:09.858131 [debug] [MainThread]: On master: COMMIT
[0m21:18:09.860522 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:18:09.862810 [debug] [MainThread]: On master: Close
[0m21:18:09.873631 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:18:09.875574 [info ] [MainThread]: 
[0m21:18:09.894875 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:18:09.896356 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:18:09.899471 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:18:09.900795 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:18:09.901732 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:18:09.912615 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:18:09.914309 [debug] [Thread-1  ]: finished collecting timing info
[0m21:18:09.917839 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:18:10.204590 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:18:10.208478 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:18:10.209403 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:18:10.210214 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:18:10.233057 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:18:10.233992 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:18:10.235485 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "warehouse"."source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:18:10.242680 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "warehouse.source" does not exist
LINE 8:     select * from "warehouse"."source"
                          ^

[0m21:18:10.245295 [debug] [Thread-1  ]: On model.dbt_.dim_types: ROLLBACK
[0m21:18:10.248827 [debug] [Thread-1  ]: finished collecting timing info
[0m21:18:10.252752 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:18:10.262922 [debug] [Thread-1  ]: Database Error in model dim_types (models/traffic_models/dim_types.sql)
  relation "warehouse.source" does not exist
  LINE 8:     select * from "warehouse"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:18:10.264358 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3f82c9910>]}
[0m21:18:10.269481 [error] [Thread-1  ]: 1 of 5 ERROR creating table model warehouse.dim_types .......................... [[31mERROR[0m in 0.37s]
[0m21:18:10.271665 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:18:10.275410 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:18:10.277477 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:18:10.281843 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.284383 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:18:10.286592 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:18:10.305761 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:18:10.310999 [debug] [Thread-1  ]: finished collecting timing info
[0m21:18:10.313530 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:18:10.349161 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:18:10.360062 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.362592 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:18:10.364848 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:18:10.381635 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:18:10.386115 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.387674 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:18:10.396536 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.01 seconds
[0m21:18:10.460143 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.469972 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:18:10.481691 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:18:10.511499 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.515155 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:18:10.521079 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:18:10.710601 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:18:10.711713 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.712730 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:18:10.726869 [debug] [Thread-1  ]: SQL status: COMMIT in 0.01 seconds
[0m21:18:10.780072 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:18:10.788904 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:18:10.816207 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.02 seconds
[0m21:18:10.821116 [debug] [Thread-1  ]: finished collecting timing info
[0m21:18:10.822275 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:18:10.825881 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3f8af61f0>]}
[0m21:18:10.827816 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.55s]
[0m21:18:10.840595 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:18:10.843781 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:18:10.845972 [info ] [Thread-1  ]: 3 of 5 SKIP relation warehouse.fct_summary ..................................... [[33mSKIP[0m]
[0m21:18:10.850578 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:18:10.869946 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:18:10.874893 [info ] [Thread-1  ]: 4 of 5 SKIP relation warehouse.fct_trajectory .................................. [[33mSKIP[0m]
[0m21:18:10.880340 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:18:10.881697 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:18:10.883841 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:18:10.890344 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:18:10.891514 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:18:10.892497 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:18:10.902929 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:18:10.904804 [debug] [Thread-1  ]: finished collecting timing info
[0m21:18:10.905989 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:18:11.098543 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:18:11.100590 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:18:11.102397 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:18:11.103346 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:18:11.125704 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:18:11.132043 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:18:11.133988 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:18:11.147332 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.01 seconds
[0m21:18:11.166252 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:18:11.167165 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:18:11.172968 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:18:11.190304 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:18:11.202400 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:18:11.205429 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:18:11.269371 [debug] [Thread-1  ]: SQL status: COMMIT in 0.06 seconds
[0m21:18:11.277925 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:18:11.278833 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:18:11.280642 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m21:18:11.288620 [debug] [Thread-1  ]: finished collecting timing info
[0m21:18:11.289616 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:18:11.292860 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a62dc8d8-f3fd-46a7-b2c1-e2759cd22814', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3f82a9d30>]}
[0m21:18:11.298114 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.40s]
[0m21:18:11.302472 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:18:11.309297 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:18:11.310320 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:11.311076 [debug] [MainThread]: On master: BEGIN
[0m21:18:11.311752 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:18:11.329131 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:18:11.330918 [debug] [MainThread]: On master: COMMIT
[0m21:18:11.333136 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:11.333902 [debug] [MainThread]: On master: COMMIT
[0m21:18:11.338814 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:18:11.339777 [debug] [MainThread]: On master: Close
[0m21:18:11.364557 [info ] [MainThread]: 
[0m21:18:11.366600 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 1.95 seconds (1.95s).
[0m21:18:11.372358 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:18:11.373301 [debug] [MainThread]: Connection 'list_warehouse' was properly closed.
[0m21:18:11.373992 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:18:11.423871 [info ] [MainThread]: 
[0m21:18:11.450902 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:18:11.456720 [info ] [MainThread]: 
[0m21:18:11.458678 [error] [MainThread]: [33mDatabase Error in model dim_types (models/traffic_models/dim_types.sql)[0m
[0m21:18:11.465415 [error] [MainThread]:   relation "warehouse.source" does not exist
[0m21:18:11.469878 [error] [MainThread]:   LINE 8:     select * from "warehouse"."source"
[0m21:18:11.471286 [error] [MainThread]:                             ^
[0m21:18:11.472596 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/dim_types.sql
[0m21:18:11.473928 [info ] [MainThread]: 
[0m21:18:11.486186 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 TOTAL=5
[0m21:18:11.487939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa05a3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa05a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3fa05a370>]}


============================== 2022-07-27 21:20:50.147062 | 9b8add4c-8101-4c32-b3f0-892f2e8a0370 ==============================
[0m21:20:50.147178 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:20:50.162022 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:20:50.163893 [debug] [MainThread]: Tracking: tracking
[0m21:20:50.325722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8bf1520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8bf1610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8bf15e0>]}
[0m21:20:50.609331 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:20:50.611186 [debug] [MainThread]: Partial parsing: updated file: dbt_://models/traffic_models/dim_types.sql
[0m21:20:50.738683 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/dim_types.sql
[0m21:20:50.913565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8ad01f0>]}
[0m21:20:50.942038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8baa9a0>]}
[0m21:20:50.943734 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:20:50.945860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8ad2fd0>]}
[0m21:20:50.965849 [info ] [MainThread]: 
[0m21:20:50.972908 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:20:50.987882 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:20:51.066193 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:20:51.067131 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:20:51.067847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:51.091229 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.02 seconds
[0m21:20:51.096348 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:20:51.110289 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:20:51.159376 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:20:51.160673 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:20:51.161614 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:20:51.180022 [debug] [ThreadPool]: SQL status: BEGIN in 0.02 seconds
[0m21:20:51.181159 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:20:51.188955 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:20:51.206194 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.02 seconds
[0m21:20:51.213291 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:20:51.224375 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:20:51.257069 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:51.263762 [debug] [MainThread]: On master: BEGIN
[0m21:20:51.269570 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:20:51.289049 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:20:51.293795 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:51.296839 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:20:51.331827 [debug] [MainThread]: SQL status: SELECT 1 in 0.03 seconds
[0m21:20:51.336105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8c07760>]}
[0m21:20:51.337413 [debug] [MainThread]: On master: ROLLBACK
[0m21:20:51.339185 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:51.340094 [debug] [MainThread]: On master: BEGIN
[0m21:20:51.342636 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:20:51.349366 [debug] [MainThread]: On master: COMMIT
[0m21:20:51.350901 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:51.352527 [debug] [MainThread]: On master: COMMIT
[0m21:20:51.356094 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:20:51.357099 [debug] [MainThread]: On master: Close
[0m21:20:51.366724 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:20:51.371111 [info ] [MainThread]: 
[0m21:20:51.438489 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:20:51.440017 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:20:51.442450 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:20:51.443615 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:20:51.444504 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:20:51.458525 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:20:51.460317 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:51.472759 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:20:51.825281 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:20:51.828847 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:20:51.835753 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:20:51.836568 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:20:51.855978 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:20:51.857049 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:20:51.857958 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:20:52.016590 [debug] [Thread-1  ]: SQL status: SELECT 6 in 0.16 seconds
[0m21:20:52.063777 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:20:52.075730 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types__dbt_tmp" rename to "dim_types"
[0m21:20:52.081196 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:20:52.221370 [debug] [Thread-1  ]: On model.dbt_.dim_types: COMMIT
[0m21:20:52.222479 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:20:52.223365 [debug] [Thread-1  ]: On model.dbt_.dim_types: COMMIT
[0m21:20:52.248360 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:20:52.267250 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:20:52.268408 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
drop table if exists "warehouse"."warehouse"."dim_types__dbt_backup" cascade
[0m21:20:52.270404 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m21:20:52.274465 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:52.275630 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:20:52.284761 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de85d8190>]}
[0m21:20:52.286519 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.dim_types .............................. [[32mSELECT 6[0m in 0.84s]
[0m21:20:52.291066 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:20:52.300849 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:20:52.303364 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:20:52.311145 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.312854 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:20:52.316455 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:20:52.338155 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:20:52.339982 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:52.341188 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:20:52.383706 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:20:52.388693 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.389928 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:20:52.390863 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:20:52.411931 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:20:52.415319 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.418031 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:20:52.430307 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.01 seconds
[0m21:20:52.454127 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.455008 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:20:52.467326 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:20:52.509337 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.510225 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:20:52.516850 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.01 seconds
[0m21:20:52.570694 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:20:52.582401 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.583143 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:20:52.614473 [debug] [Thread-1  ]: SQL status: COMMIT in 0.03 seconds
[0m21:20:52.622089 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:20:52.622972 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:20:52.659675 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.04 seconds
[0m21:20:52.663806 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:52.664853 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:20:52.666568 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8b01340>]}
[0m21:20:52.672760 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.36s]
[0m21:20:52.677248 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:20:52.681870 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:20:52.685755 [info ] [Thread-1  ]: 3 of 5 START table model warehouse.fct_summary ................................. [RUN]
[0m21:20:52.707036 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_summary"
[0m21:20:52.709415 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_summary
[0m21:20:52.710202 [debug] [Thread-1  ]: Compiling model.dbt_.fct_summary
[0m21:20:52.740048 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_summary"
[0m21:20:52.741554 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:52.742455 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_summary
[0m21:20:52.770921 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.fct_summary"
[0m21:20:52.773574 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:20:52.774419 [debug] [Thread-1  ]: On model.dbt_.fct_summary: BEGIN
[0m21:20:52.779632 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:20:52.794999 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:20:52.796520 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:20:52.798253 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */


  create  table "warehouse"."warehouse"."fct_summary__dbt_tmp"
  as (
    

with source_data as (
    select * from "warehouse"."traffic_source"."source"
),

selection as (
    select track_id, md5(types) as type_id, traveled_d, avg_speed from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.traveled_d, sel.avg_speed
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
[0m21:20:52.802315 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "traffic_source.source" does not exist
LINE 9:     select * from "warehouse"."traffic_source"."source"
                          ^

[0m21:20:52.803289 [debug] [Thread-1  ]: On model.dbt_.fct_summary: ROLLBACK
[0m21:20:52.810635 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:52.814113 [debug] [Thread-1  ]: On model.dbt_.fct_summary: Close
[0m21:20:52.822993 [debug] [Thread-1  ]: Database Error in model fct_summary (models/traffic_models/fct_summary.sql)
  relation "traffic_source.source" does not exist
  LINE 9:     select * from "warehouse"."traffic_source"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/fct_summary.sql
[0m21:20:52.824283 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de856f100>]}
[0m21:20:52.829493 [error] [Thread-1  ]: 3 of 5 ERROR creating table model warehouse.fct_summary ........................ [[31mERROR[0m in 0.12s]
[0m21:20:52.834051 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:20:52.835108 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:20:52.857301 [info ] [Thread-1  ]: 4 of 5 START table model warehouse.fct_trajectory .............................. [RUN]
[0m21:20:52.865083 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_trajectory"
[0m21:20:52.866400 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_trajectory
[0m21:20:52.868348 [debug] [Thread-1  ]: Compiling model.dbt_.fct_trajectory
[0m21:20:52.883940 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_trajectory"
[0m21:20:52.885680 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:52.900068 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_trajectory
[0m21:20:52.955069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.fct_trajectory"
[0m21:20:52.962369 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:20:52.967124 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: BEGIN
[0m21:20:52.970222 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:20:52.987208 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:20:52.990606 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:20:52.992040 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */


  create  table "warehouse"."warehouse"."fct_trajectory__dbt_tmp"
  as (
    

with source_data as (
    select * from "warehouse"."traffic_source"."source"
),

selection as (
    select track_id, md5(types) as type_id, trajectory from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.trajectory as paths
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
[0m21:20:53.008227 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "traffic_source.source" does not exist
LINE 9:     select * from "warehouse"."traffic_source"."source"
                          ^

[0m21:20:53.016013 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: ROLLBACK
[0m21:20:53.044368 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:53.048434 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: Close
[0m21:20:53.050568 [debug] [Thread-1  ]: Database Error in model fct_trajectory (models/traffic_models/fct_trajectory.sql)
  relation "traffic_source.source" does not exist
  LINE 9:     select * from "warehouse"."traffic_source"."source"
                            ^
  compiled SQL at target/run/dbt_/models/traffic_models/fct_trajectory.sql
[0m21:20:53.052022 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8513dc0>]}
[0m21:20:53.053696 [error] [Thread-1  ]: 4 of 5 ERROR creating table model warehouse.fct_trajectory ..................... [[31mERROR[0m in 0.19s]
[0m21:20:53.057669 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:20:53.058997 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:20:53.060634 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:20:53.066496 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:20:53.067589 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:20:53.069006 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:20:53.077976 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:20:53.087499 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:53.090713 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:20:53.257935 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:20:53.264810 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:20:53.266893 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:20:53.267785 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:20:53.303728 [debug] [Thread-1  ]: SQL status: BEGIN in 0.04 seconds
[0m21:20:53.304923 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:20:53.324356 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:20:53.332263 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.01 seconds
[0m21:20:53.341664 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:20:53.342539 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:20:53.351910 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:20:53.365371 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:20:53.366281 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:20:53.366976 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:20:53.391250 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:20:53.415188 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:20:53.416068 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:20:53.425702 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.01 seconds
[0m21:20:53.431737 [debug] [Thread-1  ]: finished collecting timing info
[0m21:20:53.435042 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:20:53.445872 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b8add4c-8101-4c32-b3f0-892f2e8a0370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8532d60>]}
[0m21:20:53.449490 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.38s]
[0m21:20:53.464942 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:20:53.470223 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:20:53.471867 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:53.473046 [debug] [MainThread]: On master: BEGIN
[0m21:20:53.473991 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:20:53.487916 [debug] [MainThread]: SQL status: BEGIN in 0.01 seconds
[0m21:20:53.492874 [debug] [MainThread]: On master: COMMIT
[0m21:20:53.499349 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:53.504065 [debug] [MainThread]: On master: COMMIT
[0m21:20:53.513882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:20:53.519569 [debug] [MainThread]: On master: Close
[0m21:20:53.527051 [info ] [MainThread]: 
[0m21:20:53.540948 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 2.56 seconds (2.56s).
[0m21:20:53.556415 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:20:53.561215 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:20:53.611577 [info ] [MainThread]: 
[0m21:20:53.621395 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m21:20:53.622865 [info ] [MainThread]: 
[0m21:20:53.632274 [error] [MainThread]: [33mDatabase Error in model fct_summary (models/traffic_models/fct_summary.sql)[0m
[0m21:20:53.633838 [error] [MainThread]:   relation "traffic_source.source" does not exist
[0m21:20:53.635074 [error] [MainThread]:   LINE 9:     select * from "warehouse"."traffic_source"."source"
[0m21:20:53.636320 [error] [MainThread]:                             ^
[0m21:20:53.637533 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/fct_summary.sql
[0m21:20:53.638769 [info ] [MainThread]: 
[0m21:20:53.640019 [error] [MainThread]: [33mDatabase Error in model fct_trajectory (models/traffic_models/fct_trajectory.sql)[0m
[0m21:20:53.650616 [error] [MainThread]:   relation "traffic_source.source" does not exist
[0m21:20:53.651859 [error] [MainThread]:   LINE 9:     select * from "warehouse"."traffic_source"."source"
[0m21:20:53.653170 [error] [MainThread]:                             ^
[0m21:20:53.654377 [error] [MainThread]:   compiled SQL at target/run/dbt_/models/traffic_models/fct_trajectory.sql
[0m21:20:53.655657 [info ] [MainThread]: 
[0m21:20:53.657004 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 TOTAL=5
[0m21:20:53.658528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8b6c460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8b6c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de8b6c430>]}


============================== 2022-07-27 21:23:24.914759 | a676c8f2-cadb-40cb-afcb-8120b89d9038 ==============================
[0m21:23:24.914901 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:23:24.940533 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:23:24.943326 [debug] [MainThread]: Tracking: tracking
[0m21:23:25.132732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39419b8580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39419b8670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39419b8640>]}
[0m21:23:25.604412 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:23:25.606269 [debug] [MainThread]: Partial parsing: updated file: dbt_://models/traffic_models/fct_trajectory.sql
[0m21:23:25.607577 [debug] [MainThread]: Partial parsing: updated file: dbt_://models/traffic_models/fct_summary.sql
[0m21:23:25.663061 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_trajectory.sql
[0m21:23:25.741015 [debug] [MainThread]: 1699: static parser successfully parsed traffic_models/fct_summary.sql
[0m21:23:25.793503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f394186aa00>]}
[0m21:23:25.820059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39418f2670>]}
[0m21:23:25.821504 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:23:25.823106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39418f25e0>]}
[0m21:23:25.828820 [info ] [MainThread]: 
[0m21:23:25.831261 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:23:25.835284 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:23:25.876639 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:23:25.877583 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:23:25.878339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:23:25.957778 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.08 seconds
[0m21:23:25.962667 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:23:25.985518 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:23:26.055464 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:23:26.056584 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:23:26.057460 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:23:26.071750 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
[0m21:23:26.075061 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:23:26.077918 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:23:26.090082 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.01 seconds
[0m21:23:26.113696 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:23:26.124462 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:23:26.165107 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:26.166027 [debug] [MainThread]: On master: BEGIN
[0m21:23:26.166729 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:23:26.185494 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:23:26.186429 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:26.187140 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:23:26.226658 [debug] [MainThread]: SQL status: SELECT 1 in 0.04 seconds
[0m21:23:26.230632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3941931820>]}
[0m21:23:26.231909 [debug] [MainThread]: On master: ROLLBACK
[0m21:23:26.234112 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:26.235283 [debug] [MainThread]: On master: BEGIN
[0m21:23:26.238716 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:23:26.240186 [debug] [MainThread]: On master: COMMIT
[0m21:23:26.242289 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:26.243495 [debug] [MainThread]: On master: COMMIT
[0m21:23:26.245067 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:23:26.246024 [debug] [MainThread]: On master: Close
[0m21:23:26.254397 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:23:26.256031 [info ] [MainThread]: 
[0m21:23:26.290953 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:23:26.292353 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.dim_types ................................... [RUN]
[0m21:23:26.294603 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:23:26.295578 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:23:26.296486 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:23:26.306861 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:23:26.308447 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:26.320290 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:23:26.688057 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:23:26.702814 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:23:26.703768 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:23:26.704522 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:23:26.725177 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:23:26.727387 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:23:26.728886 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:23:26.828681 [debug] [Thread-1  ]: SQL status: SELECT 6 in 0.1 seconds
[0m21:23:26.925458 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:23:26.926369 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types" rename to "dim_types__dbt_backup"
[0m21:23:26.932389 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.01 seconds
[0m21:23:26.946569 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:23:26.947466 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types__dbt_tmp" rename to "dim_types"
[0m21:23:26.953694 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.01 seconds
[0m21:23:27.189386 [debug] [Thread-1  ]: On model.dbt_.dim_types: COMMIT
[0m21:23:27.190335 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:23:27.191062 [debug] [Thread-1  ]: On model.dbt_.dim_types: COMMIT
[0m21:23:27.599219 [debug] [Thread-1  ]: SQL status: COMMIT in 0.41 seconds
[0m21:23:27.624086 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:23:27.625107 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
drop table if exists "warehouse"."warehouse"."dim_types__dbt_backup" cascade
[0m21:23:27.767093 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.14 seconds
[0m21:23:27.771300 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:27.772517 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:23:27.782233 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f394035b130>]}
[0m21:23:27.784214 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.dim_types .............................. [[32mSELECT 6[0m in 1.49s]
[0m21:23:27.786580 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:23:27.788054 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:23:27.793548 [info ] [Thread-1  ]: 2 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
[0m21:23:27.795974 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:27.804793 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:23:27.805805 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:23:27.825494 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:23:27.829534 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:27.832978 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:23:27.904605 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_first_dbt_model"
[0m21:23:27.906202 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:27.916820 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: BEGIN
[0m21:23:27.918040 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:23:27.932616 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
[0m21:23:27.934329 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:27.937546 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */


  create  table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
[0m21:23:27.944422 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.01 seconds
[0m21:23:27.966496 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:27.967390 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:23:27.969542 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:23:27.978840 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:27.979826 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
alter table "warehouse"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:23:27.982130 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:23:27.991852 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:23:27.992863 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:27.993581 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: COMMIT
[0m21:23:28.201033 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
[0m21:23:28.212005 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_first_dbt_model"
[0m21:23:28.239075 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_first_dbt_model"} */
drop table if exists "warehouse"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m21:23:28.268375 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.02 seconds
[0m21:23:28.273387 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:28.274536 [debug] [Thread-1  ]: On model.dbt_.my_first_dbt_model: Close
[0m21:23:28.283448 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3941888970>]}
[0m21:23:28.285199 [info ] [Thread-1  ]: 2 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 0.49s]
[0m21:23:28.291873 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:23:28.296481 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:23:28.300897 [info ] [Thread-1  ]: 3 of 5 START table model warehouse.fct_summary ................................. [RUN]
[0m21:23:28.308053 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_summary"
[0m21:23:28.315320 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_summary
[0m21:23:28.325112 [debug] [Thread-1  ]: Compiling model.dbt_.fct_summary
[0m21:23:28.360623 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_summary"
[0m21:23:28.369246 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:28.370807 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_summary
[0m21:23:28.412640 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.fct_summary"
[0m21:23:28.414449 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:23:28.415328 [debug] [Thread-1  ]: On model.dbt_.fct_summary: BEGIN
[0m21:23:28.416240 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:23:28.428577 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
[0m21:23:28.432485 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:23:28.437712 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */


  create  table "warehouse"."warehouse"."fct_summary__dbt_tmp"
  as (
    

with source_data as (
    select * from "source"
),

selection as (
    select track_id, md5(types) as type_id, traveled_d, avg_speed from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.traveled_d, sel.avg_speed
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
[0m21:23:28.496231 [debug] [Thread-1  ]: SQL status: SELECT 922 in 0.05 seconds
[0m21:23:28.513704 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:23:28.515856 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
alter table "warehouse"."warehouse"."fct_summary__dbt_tmp" rename to "fct_summary"
[0m21:23:28.521670 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:23:28.535946 [debug] [Thread-1  ]: On model.dbt_.fct_summary: COMMIT
[0m21:23:28.540005 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:23:28.542571 [debug] [Thread-1  ]: On model.dbt_.fct_summary: COMMIT
[0m21:23:28.568195 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:23:28.582361 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:23:28.588404 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
drop table if exists "warehouse"."warehouse"."fct_summary__dbt_backup" cascade
[0m21:23:28.593744 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m21:23:28.606960 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:28.611453 [debug] [Thread-1  ]: On model.dbt_.fct_summary: Close
[0m21:23:28.616634 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39402ec6d0>]}
[0m21:23:28.624675 [info ] [Thread-1  ]: 3 of 5 OK created table model warehouse.fct_summary ............................ [[32mSELECT 922[0m in 0.31s]
[0m21:23:28.629119 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:23:28.635865 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:23:28.645892 [info ] [Thread-1  ]: 4 of 5 START table model warehouse.fct_trajectory .............................. [RUN]
[0m21:23:28.649787 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_trajectory"
[0m21:23:28.673168 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_trajectory
[0m21:23:28.692417 [debug] [Thread-1  ]: Compiling model.dbt_.fct_trajectory
[0m21:23:28.771084 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_trajectory"
[0m21:23:28.776133 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:28.777142 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_trajectory
[0m21:23:28.823481 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.fct_trajectory"
[0m21:23:28.845351 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:23:28.846379 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: BEGIN
[0m21:23:28.847215 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:23:28.865049 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:23:28.866640 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:23:28.867599 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */


  create  table "warehouse"."warehouse"."fct_trajectory__dbt_tmp"
  as (
    

with source_data as (
    select * from "source"
),

selection as (
    select track_id, md5(types) as type_id, trajectory from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.trajectory as paths
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
[0m21:23:32.825530 [debug] [Thread-1  ]: SQL status: SELECT 922 in 3.95 seconds
[0m21:23:32.838953 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:23:32.839837 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
alter table "warehouse"."warehouse"."fct_trajectory__dbt_tmp" rename to "fct_trajectory"
[0m21:23:32.841906 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:23:32.853719 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: COMMIT
[0m21:23:32.854854 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:23:32.855741 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: COMMIT
[0m21:23:33.154016 [debug] [Thread-1  ]: SQL status: COMMIT in 0.3 seconds
[0m21:23:33.202160 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:23:33.203228 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
drop table if exists "warehouse"."warehouse"."fct_trajectory__dbt_backup" cascade
[0m21:23:33.205580 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m21:23:33.214894 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:33.217165 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: Close
[0m21:23:33.221502 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39402a3130>]}
[0m21:23:33.223392 [info ] [Thread-1  ]: 4 of 5 OK created table model warehouse.fct_trajectory ......................... [[32mSELECT 922[0m in 4.57s]
[0m21:23:33.226582 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:23:33.227896 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:23:33.230269 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
[0m21:23:33.234343 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:23:33.235501 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:23:33.237176 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:23:33.268517 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:23:33.270384 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:33.271505 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:23:33.432436 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.my_second_dbt_model"
[0m21:23:33.445664 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:23:33.446583 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: BEGIN
[0m21:23:33.447285 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:23:33.474718 [debug] [Thread-1  ]: SQL status: BEGIN in 0.03 seconds
[0m21:23:33.475830 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:23:33.481598 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */

  create view "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "warehouse"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m21:23:33.489522 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.01 seconds
[0m21:23:33.515545 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:23:33.516494 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
alter table "warehouse"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:23:33.520366 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:23:33.552479 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:23:33.553445 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:23:33.554179 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: COMMIT
[0m21:23:33.732420 [debug] [Thread-1  ]: SQL status: COMMIT in 0.18 seconds
[0m21:23:33.744282 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.my_second_dbt_model"
[0m21:23:33.745194 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.my_second_dbt_model"} */
drop view if exists "warehouse"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m21:23:33.760606 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.01 seconds
[0m21:23:33.768673 [debug] [Thread-1  ]: finished collecting timing info
[0m21:23:33.769661 [debug] [Thread-1  ]: On model.dbt_.my_second_dbt_model: Close
[0m21:23:33.782408 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a676c8f2-cadb-40cb-afcb-8120b89d9038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39413f3100>]}
[0m21:23:33.789584 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 0.55s]
[0m21:23:33.796892 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:23:33.802258 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:23:33.803483 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:33.824829 [debug] [MainThread]: On master: BEGIN
[0m21:23:33.825889 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:23:33.851210 [debug] [MainThread]: SQL status: BEGIN in 0.03 seconds
[0m21:23:33.852396 [debug] [MainThread]: On master: COMMIT
[0m21:23:33.855166 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:33.857985 [debug] [MainThread]: On master: COMMIT
[0m21:23:33.864385 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:23:33.868473 [debug] [MainThread]: On master: Close
[0m21:23:33.873945 [info ] [MainThread]: 
[0m21:23:33.885251 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 8.04 seconds (8.04s).
[0m21:23:33.892634 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:23:33.895804 [debug] [MainThread]: Connection 'list_warehouse' was properly closed.
[0m21:23:33.906055 [debug] [MainThread]: Connection 'model.dbt_.my_second_dbt_model' was properly closed.
[0m21:23:33.958805 [info ] [MainThread]: 
[0m21:23:33.967208 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:23:33.972469 [info ] [MainThread]: 
[0m21:23:33.975525 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m21:23:33.981075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39418f2520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3941880e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f394183f610>]}


============================== 2022-07-27 21:26:16.553911 | 016b495a-9ff1-4450-9e2b-8900dbe57597 ==============================
[0m21:26:16.554034 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:26:16.563072 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m21:26:16.564100 [debug] [MainThread]: Tracking: tracking
[0m21:26:16.775196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644848550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644848640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644848610>]}
[0m21:26:16.962694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:26:16.963876 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:26:16.988387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '016b495a-9ff1-4450-9e2b-8900dbe57597', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644732a00>]}
[0m21:26:17.026099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '016b495a-9ff1-4450-9e2b-8900dbe57597', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644788e20>]}
[0m21:26:17.027651 [info ] [MainThread]: Found 5 models, 4 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:26:17.029595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '016b495a-9ff1-4450-9e2b-8900dbe57597', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644788d30>]}
[0m21:26:17.038026 [info ] [MainThread]: 
[0m21:26:17.043606 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:26:17.047954 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:26:17.114424 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:26:17.119491 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:26:17.120754 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:26:17.134964 [debug] [ThreadPool]: SQL status: BEGIN in 0.01 seconds
[0m21:26:17.141351 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:26:17.146175 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:26:17.158169 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.01 seconds
[0m21:26:17.165131 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:26:17.171917 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:26:17.219562 [debug] [MainThread]: Using postgres connection "master"
[0m21:26:17.222779 [debug] [MainThread]: On master: BEGIN
[0m21:26:17.226614 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:26:17.244341 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:26:17.246698 [debug] [MainThread]: Using postgres connection "master"
[0m21:26:17.247600 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:26:17.287318 [debug] [MainThread]: SQL status: SELECT 1 in 0.04 seconds
[0m21:26:17.291398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '016b495a-9ff1-4450-9e2b-8900dbe57597', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb64485b7c0>]}
[0m21:26:17.292984 [debug] [MainThread]: On master: ROLLBACK
[0m21:26:17.294615 [debug] [MainThread]: On master: Close
[0m21:26:17.301869 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:26:17.303880 [info ] [MainThread]: 
[0m21:26:17.333778 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:26:17.335354 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:26:17.336384 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:26:17.337253 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:26:17.346380 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:26:17.348249 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.349567 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:26:17.352739 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.361584 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:26:17.363100 [debug] [Thread-1  ]: Began running node model.dbt_.my_first_dbt_model
[0m21:26:17.365416 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_first_dbt_model"
[0m21:26:17.366516 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_first_dbt_model
[0m21:26:17.367443 [debug] [Thread-1  ]: Compiling model.dbt_.my_first_dbt_model
[0m21:26:17.386501 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_first_dbt_model"
[0m21:26:17.393902 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.395200 [debug] [Thread-1  ]: Began executing node model.dbt_.my_first_dbt_model
[0m21:26:17.396241 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.398191 [debug] [Thread-1  ]: Finished running node model.dbt_.my_first_dbt_model
[0m21:26:17.403017 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:26:17.406139 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_summary"
[0m21:26:17.412820 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_summary
[0m21:26:17.413898 [debug] [Thread-1  ]: Compiling model.dbt_.fct_summary
[0m21:26:17.443288 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_summary"
[0m21:26:17.453506 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.454677 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_summary
[0m21:26:17.461608 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.465248 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:26:17.469185 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:26:17.477417 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_trajectory"
[0m21:26:17.478534 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_trajectory
[0m21:26:17.479470 [debug] [Thread-1  ]: Compiling model.dbt_.fct_trajectory
[0m21:26:17.496569 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_trajectory"
[0m21:26:17.502535 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.503668 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_trajectory
[0m21:26:17.504722 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.506626 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:26:17.511958 [debug] [Thread-1  ]: Began running node model.dbt_.my_second_dbt_model
[0m21:26:17.514161 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.my_second_dbt_model"
[0m21:26:17.516950 [debug] [Thread-1  ]: Began compiling node model.dbt_.my_second_dbt_model
[0m21:26:17.518038 [debug] [Thread-1  ]: Compiling model.dbt_.my_second_dbt_model
[0m21:26:17.535753 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.my_second_dbt_model"
[0m21:26:17.537665 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.541515 [debug] [Thread-1  ]: Began executing node model.dbt_.my_second_dbt_model
[0m21:26:17.542924 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.546375 [debug] [Thread-1  ]: Finished running node model.dbt_.my_second_dbt_model
[0m21:26:17.547689 [debug] [Thread-1  ]: Began running node test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:26:17.550163 [debug] [Thread-1  ]: Acquiring new postgres connection "test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710"
[0m21:26:17.552472 [debug] [Thread-1  ]: Began compiling node test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:26:17.555552 [debug] [Thread-1  ]: Compiling test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:26:17.675162 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710"
[0m21:26:17.677012 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.677958 [debug] [Thread-1  ]: Began executing node test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:26:17.678768 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.680603 [debug] [Thread-1  ]: Finished running node test.dbt_.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:26:17.681673 [debug] [Thread-1  ]: Began running node test.dbt_.unique_my_first_dbt_model_id.16e066b321
[0m21:26:17.683522 [debug] [Thread-1  ]: Acquiring new postgres connection "test.dbt_.unique_my_first_dbt_model_id.16e066b321"
[0m21:26:17.684528 [debug] [Thread-1  ]: Began compiling node test.dbt_.unique_my_first_dbt_model_id.16e066b321
[0m21:26:17.685301 [debug] [Thread-1  ]: Compiling test.dbt_.unique_my_first_dbt_model_id.16e066b321
[0m21:26:17.715970 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_.unique_my_first_dbt_model_id.16e066b321"
[0m21:26:17.717481 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.718388 [debug] [Thread-1  ]: Began executing node test.dbt_.unique_my_first_dbt_model_id.16e066b321
[0m21:26:17.720467 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.722282 [debug] [Thread-1  ]: Finished running node test.dbt_.unique_my_first_dbt_model_id.16e066b321
[0m21:26:17.723324 [debug] [Thread-1  ]: Began running node test.dbt_.not_null_my_second_dbt_model_id.151b76d778
[0m21:26:17.725164 [debug] [Thread-1  ]: Acquiring new postgres connection "test.dbt_.not_null_my_second_dbt_model_id.151b76d778"
[0m21:26:17.726248 [debug] [Thread-1  ]: Began compiling node test.dbt_.not_null_my_second_dbt_model_id.151b76d778
[0m21:26:17.727186 [debug] [Thread-1  ]: Compiling test.dbt_.not_null_my_second_dbt_model_id.151b76d778
[0m21:26:17.745985 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_.not_null_my_second_dbt_model_id.151b76d778"
[0m21:26:17.747760 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.749145 [debug] [Thread-1  ]: Began executing node test.dbt_.not_null_my_second_dbt_model_id.151b76d778
[0m21:26:17.750183 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.752074 [debug] [Thread-1  ]: Finished running node test.dbt_.not_null_my_second_dbt_model_id.151b76d778
[0m21:26:17.753353 [debug] [Thread-1  ]: Began running node test.dbt_.unique_my_second_dbt_model_id.57a0f8c493
[0m21:26:17.755556 [debug] [Thread-1  ]: Acquiring new postgres connection "test.dbt_.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:26:17.756726 [debug] [Thread-1  ]: Began compiling node test.dbt_.unique_my_second_dbt_model_id.57a0f8c493
[0m21:26:17.757660 [debug] [Thread-1  ]: Compiling test.dbt_.unique_my_second_dbt_model_id.57a0f8c493
[0m21:26:17.773297 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:26:17.774948 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.775995 [debug] [Thread-1  ]: Began executing node test.dbt_.unique_my_second_dbt_model_id.57a0f8c493
[0m21:26:17.777049 [debug] [Thread-1  ]: finished collecting timing info
[0m21:26:17.778958 [debug] [Thread-1  ]: Finished running node test.dbt_.unique_my_second_dbt_model_id.57a0f8c493
[0m21:26:17.782462 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:26:17.783353 [debug] [MainThread]: Connection 'test.dbt_.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m21:26:17.807238 [info ] [MainThread]: Done.
[0m21:26:17.864839 [debug] [MainThread]: Acquiring new postgres connection "generate_catalog"
[0m21:26:17.865873 [info ] [MainThread]: Building catalog
[0m21:26:17.883317 [debug] [ThreadPool]: Acquiring new postgres connection "warehouse.information_schema"
[0m21:26:17.959344 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m21:26:17.960899 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m21:26:17.961961 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:26:17.979299 [debug] [ThreadPool]: SQL status: BEGIN in 0.02 seconds
[0m21:26:17.983030 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m21:26:17.985419 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)

    where (upper(sch.nspname) = upper('warehouse') or upper(sch.nspname) = upper('traffic_source'))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m21:26:18.442086 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.45 seconds
[0m21:26:18.511323 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m21:26:18.513793 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m21:26:18.561310 [info ] [MainThread]: Catalog written to /home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/target/catalog.json
[0m21:26:18.563307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb644848550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb643e90ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb643e90d90>]}
[0m21:26:21.692619 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m21:26:21.694461 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.


============================== 2022-07-27 21:26:47.108713 | 501303cb-3088-4b70-9289-bc0960616cda ==============================
[0m21:26:47.108833 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:26:47.127122 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
[0m21:26:47.128143 [debug] [MainThread]: Tracking: tracking
[0m21:26:47.390794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1da0c18670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1da0c18760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1da0c18730>]}
[0m21:26:47.407920 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
[0m21:26:47.413581 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
[0m21:26:47.415170 [info ] [MainThread]: 
[0m21:26:47.423949 [info ] [MainThread]: 
[0m21:26:47.426885 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2022-07-27 21:29:03.002006 | 9029f63b-320e-413e-9865-cf604216577b ==============================
[0m21:29:03.002127 [info ] [MainThread]: Running with dbt=1.2.0
[0m21:29:03.014055 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/home/bini/10_acad/week_12/ELT_Pipeline_Project_2/dbt_/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m21:29:03.016650 [debug] [MainThread]: Tracking: tracking
[0m21:29:03.224704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71f154c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71f155b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71f15580>]}
[0m21:29:03.415142 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 0 files added, 0 files changed.
[0m21:29:03.416668 [debug] [MainThread]: Partial parsing: deleted file: dbt_://models/example/my_first_dbt_model.sql
[0m21:29:03.417548 [debug] [MainThread]: Partial parsing: deleted file: dbt_://models/example/my_second_dbt_model.sql
[0m21:29:03.437810 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_.example

[0m21:29:03.461434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71e04970>]}
[0m21:29:03.486401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71e4f1f0>]}
[0m21:29:03.487863 [info ] [MainThread]: Found 3 models, 0 tests, 0 snapshots, 0 analyses, 256 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m21:29:03.489547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71e4f2e0>]}
[0m21:29:03.494801 [info ] [MainThread]: 
[0m21:29:03.497400 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:29:03.517496 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse"
[0m21:29:03.629220 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m21:29:03.630423 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:29:03.631360 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:29:03.651131 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.02 seconds
[0m21:29:03.661517 [debug] [ThreadPool]: On list_warehouse: Close
[0m21:29:03.674946 [debug] [ThreadPool]: Acquiring new postgres connection "list_warehouse_warehouse"
[0m21:29:03.701617 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:29:03.712340 [debug] [ThreadPool]: On list_warehouse_warehouse: BEGIN
[0m21:29:03.713465 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:29:03.729987 [debug] [ThreadPool]: SQL status: BEGIN in 0.02 seconds
[0m21:29:03.731074 [debug] [ThreadPool]: Using postgres connection "list_warehouse_warehouse"
[0m21:29:03.733555 [debug] [ThreadPool]: On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m21:29:03.746222 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.01 seconds
[0m21:29:03.754017 [debug] [ThreadPool]: On list_warehouse_warehouse: ROLLBACK
[0m21:29:03.761232 [debug] [ThreadPool]: On list_warehouse_warehouse: Close
[0m21:29:03.802220 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:03.803146 [debug] [MainThread]: On master: BEGIN
[0m21:29:03.803843 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:29:03.839207 [debug] [MainThread]: SQL status: BEGIN in 0.04 seconds
[0m21:29:03.846546 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:03.850329 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:29:03.903369 [debug] [MainThread]: SQL status: SELECT 1 in 0.05 seconds
[0m21:29:03.907321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71e8e430>]}
[0m21:29:03.909578 [debug] [MainThread]: On master: ROLLBACK
[0m21:29:03.913158 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:03.914510 [debug] [MainThread]: On master: BEGIN
[0m21:29:03.918550 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m21:29:03.921133 [debug] [MainThread]: On master: COMMIT
[0m21:29:03.922231 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:03.924186 [debug] [MainThread]: On master: COMMIT
[0m21:29:03.927829 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:29:03.929393 [debug] [MainThread]: On master: Close
[0m21:29:03.932872 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:29:03.940467 [info ] [MainThread]: 
[0m21:29:03.994250 [debug] [Thread-1  ]: Began running node model.dbt_.dim_types
[0m21:29:03.995664 [info ] [Thread-1  ]: 1 of 3 START table model warehouse.dim_types ................................... [RUN]
[0m21:29:03.998427 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.dim_types"
[0m21:29:03.999623 [debug] [Thread-1  ]: Began compiling node model.dbt_.dim_types
[0m21:29:04.000564 [debug] [Thread-1  ]: Compiling model.dbt_.dim_types
[0m21:29:04.017343 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.dim_types"
[0m21:29:04.018849 [debug] [Thread-1  ]: finished collecting timing info
[0m21:29:04.025086 [debug] [Thread-1  ]: Began executing node model.dbt_.dim_types
[0m21:29:04.429499 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.dim_types"
[0m21:29:04.431490 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:29:04.433330 [debug] [Thread-1  ]: On model.dbt_.dim_types: BEGIN
[0m21:29:04.434493 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:29:04.447130 [debug] [Thread-1  ]: SQL status: BEGIN in 0.01 seconds
[0m21:29:04.449840 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:29:04.451067 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
[0m21:29:04.511420 [debug] [Thread-1  ]: SQL status: SELECT 6 in 0.06 seconds
[0m21:29:04.536357 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:29:04.537451 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types" rename to "dim_types__dbt_backup"
[0m21:29:04.539767 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:29:04.550486 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:29:04.551727 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types__dbt_tmp" rename to "dim_types"
[0m21:29:04.554059 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:29:04.657697 [debug] [Thread-1  ]: On model.dbt_.dim_types: COMMIT
[0m21:29:04.658832 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:29:04.659733 [debug] [Thread-1  ]: On model.dbt_.dim_types: COMMIT
[0m21:29:04.685823 [debug] [Thread-1  ]: SQL status: COMMIT in 0.03 seconds
[0m21:29:04.704878 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.dim_types"
[0m21:29:04.705964 [debug] [Thread-1  ]: On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
drop table if exists "warehouse"."warehouse"."dim_types__dbt_backup" cascade
[0m21:29:04.720190 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.01 seconds
[0m21:29:04.724520 [debug] [Thread-1  ]: finished collecting timing info
[0m21:29:04.725687 [debug] [Thread-1  ]: On model.dbt_.dim_types: Close
[0m21:29:04.734165 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71569d90>]}
[0m21:29:04.735915 [info ] [Thread-1  ]: 1 of 3 OK created table model warehouse.dim_types .............................. [[32mSELECT 6[0m in 0.74s]
[0m21:29:04.740020 [debug] [Thread-1  ]: Finished running node model.dbt_.dim_types
[0m21:29:04.752509 [debug] [Thread-1  ]: Began running node model.dbt_.fct_summary
[0m21:29:04.758670 [info ] [Thread-1  ]: 2 of 3 START table model warehouse.fct_summary ................................. [RUN]
[0m21:29:04.762474 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_summary"
[0m21:29:04.764717 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_summary
[0m21:29:04.767117 [debug] [Thread-1  ]: Compiling model.dbt_.fct_summary
[0m21:29:04.786741 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_summary"
[0m21:29:04.794474 [debug] [Thread-1  ]: finished collecting timing info
[0m21:29:04.797062 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_summary
[0m21:29:04.835245 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.fct_summary"
[0m21:29:04.837227 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:29:04.838550 [debug] [Thread-1  ]: On model.dbt_.fct_summary: BEGIN
[0m21:29:04.839537 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:29:04.856937 [debug] [Thread-1  ]: SQL status: BEGIN in 0.02 seconds
[0m21:29:04.858705 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:29:04.862311 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */


  create  table "warehouse"."warehouse"."fct_summary__dbt_tmp"
  as (
    

with source_data as (
    select * from "source"
),

selection as (
    select track_id, md5(types) as type_id, traveled_d, avg_speed from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.traveled_d, sel.avg_speed
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
[0m21:29:04.925655 [debug] [Thread-1  ]: SQL status: SELECT 922 in 0.06 seconds
[0m21:29:04.954352 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:29:04.963268 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
alter table "warehouse"."warehouse"."fct_summary" rename to "fct_summary__dbt_backup"
[0m21:29:04.970234 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:29:05.000059 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:29:05.001026 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
alter table "warehouse"."warehouse"."fct_summary__dbt_tmp" rename to "fct_summary"
[0m21:29:05.010088 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.01 seconds
[0m21:29:05.067107 [debug] [Thread-1  ]: On model.dbt_.fct_summary: COMMIT
[0m21:29:05.068029 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:29:05.073685 [debug] [Thread-1  ]: On model.dbt_.fct_summary: COMMIT
[0m21:29:05.097148 [debug] [Thread-1  ]: SQL status: COMMIT in 0.02 seconds
[0m21:29:05.125135 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_summary"
[0m21:29:05.126133 [debug] [Thread-1  ]: On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
drop table if exists "warehouse"."warehouse"."fct_summary__dbt_backup" cascade
[0m21:29:05.205353 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.08 seconds
[0m21:29:05.210623 [debug] [Thread-1  ]: finished collecting timing info
[0m21:29:05.211795 [debug] [Thread-1  ]: On model.dbt_.fct_summary: Close
[0m21:29:05.215198 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b705245e0>]}
[0m21:29:05.216983 [info ] [Thread-1  ]: 2 of 3 OK created table model warehouse.fct_summary ............................ [[32mSELECT 922[0m in 0.45s]
[0m21:29:05.250056 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_summary
[0m21:29:05.253783 [debug] [Thread-1  ]: Began running node model.dbt_.fct_trajectory
[0m21:29:05.260207 [info ] [Thread-1  ]: 3 of 3 START table model warehouse.fct_trajectory .............................. [RUN]
[0m21:29:05.268650 [debug] [Thread-1  ]: Acquiring new postgres connection "model.dbt_.fct_trajectory"
[0m21:29:05.270953 [debug] [Thread-1  ]: Began compiling node model.dbt_.fct_trajectory
[0m21:29:05.275084 [debug] [Thread-1  ]: Compiling model.dbt_.fct_trajectory
[0m21:29:05.295548 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_.fct_trajectory"
[0m21:29:05.303106 [debug] [Thread-1  ]: finished collecting timing info
[0m21:29:05.307960 [debug] [Thread-1  ]: Began executing node model.dbt_.fct_trajectory
[0m21:29:05.368955 [debug] [Thread-1  ]: Writing runtime SQL for node "model.dbt_.fct_trajectory"
[0m21:29:05.370547 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:29:05.376668 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: BEGIN
[0m21:29:05.377427 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:29:05.406328 [debug] [Thread-1  ]: SQL status: BEGIN in 0.03 seconds
[0m21:29:05.407598 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:29:05.408429 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */


  create  table "warehouse"."warehouse"."fct_trajectory__dbt_tmp"
  as (
    

with source_data as (
    select * from "source"
),

selection as (
    select track_id, md5(types) as type_id, trajectory from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.trajectory as paths
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
[0m21:29:08.279601 [debug] [Thread-1  ]: SQL status: SELECT 922 in 2.87 seconds
[0m21:29:08.294761 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:29:08.295659 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
alter table "warehouse"."warehouse"."fct_trajectory" rename to "fct_trajectory__dbt_backup"
[0m21:29:08.300470 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:29:08.311663 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:29:08.313166 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
alter table "warehouse"."warehouse"."fct_trajectory__dbt_tmp" rename to "fct_trajectory"
[0m21:29:08.315950 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m21:29:08.328321 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: COMMIT
[0m21:29:08.329398 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:29:08.330336 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: COMMIT
[0m21:29:08.368289 [debug] [Thread-1  ]: SQL status: COMMIT in 0.04 seconds
[0m21:29:08.376276 [debug] [Thread-1  ]: Using postgres connection "model.dbt_.fct_trajectory"
[0m21:29:08.377725 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "1.2.0", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
drop table if exists "warehouse"."warehouse"."fct_trajectory__dbt_backup" cascade
[0m21:29:08.435389 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.06 seconds
[0m21:29:08.442629 [debug] [Thread-1  ]: finished collecting timing info
[0m21:29:08.444296 [debug] [Thread-1  ]: On model.dbt_.fct_trajectory: Close
[0m21:29:08.457247 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9029f63b-320e-413e-9865-cf604216577b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b704bc580>]}
[0m21:29:08.458943 [info ] [Thread-1  ]: 3 of 3 OK created table model warehouse.fct_trajectory ......................... [[32mSELECT 922[0m in 3.19s]
[0m21:29:08.476650 [debug] [Thread-1  ]: Finished running node model.dbt_.fct_trajectory
[0m21:29:08.488931 [debug] [MainThread]: Acquiring new postgres connection "master"
[0m21:29:08.490116 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:08.490883 [debug] [MainThread]: On master: BEGIN
[0m21:29:08.491572 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:29:08.508828 [debug] [MainThread]: SQL status: BEGIN in 0.02 seconds
[0m21:29:08.509793 [debug] [MainThread]: On master: COMMIT
[0m21:29:08.510515 [debug] [MainThread]: Using postgres connection "master"
[0m21:29:08.511202 [debug] [MainThread]: On master: COMMIT
[0m21:29:08.512656 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m21:29:08.513618 [debug] [MainThread]: On master: Close
[0m21:29:08.515756 [info ] [MainThread]: 
[0m21:29:08.521781 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 5.02 seconds (5.02s).
[0m21:29:08.524233 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:29:08.526922 [debug] [MainThread]: Connection 'model.dbt_.fct_trajectory' was properly closed.
[0m21:29:08.589151 [info ] [MainThread]: 
[0m21:29:08.595585 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:29:08.597390 [info ] [MainThread]: 
[0m21:29:08.598842 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m21:29:08.600442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71e8e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7156c160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b71ddcd60>]}
2022-07-28 00:32:11.150893 (MainThread): Running with dbt=0.16.1
2022-07-28 00:32:11.514781 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/local/airflow/dbt_/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-07-28 00:32:11.566477 (MainThread): Tracking: tracking
2022-07-28 00:32:11.698661 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d790e6510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d7913d4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d78f87850>]}
2022-07-28 00:32:11.861962 (MainThread): Partial parsing not enabled
2022-07-28 00:32:11.940918 (MainThread): Parsing macros/core.sql
2022-07-28 00:32:11.962447 (MainThread): Parsing macros/materializations/helpers.sql
2022-07-28 00:32:11.997903 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-07-28 00:32:12.007088 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-07-28 00:32:12.147313 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-07-28 00:32:12.246055 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-07-28 00:32:12.276333 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-07-28 00:32:12.286892 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-07-28 00:32:12.394453 (MainThread): Parsing macros/materializations/common/merge.sql
2022-07-28 00:32:12.458764 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-07-28 00:32:12.489309 (MainThread): Parsing macros/materializations/view/view.sql
2022-07-28 00:32:12.532735 (MainThread): Parsing macros/materializations/table/table.sql
2022-07-28 00:32:12.567577 (MainThread): Parsing macros/adapters/common.sql
2022-07-28 00:32:12.767575 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-07-28 00:32:12.773897 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-07-28 00:32:12.784847 (MainThread): Parsing macros/etc/get_relation_comment.sql
2022-07-28 00:32:12.795968 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-07-28 00:32:12.801033 (MainThread): Parsing macros/etc/is_incremental.sql
2022-07-28 00:32:12.811262 (MainThread): Parsing macros/etc/query.sql
2022-07-28 00:32:12.819732 (MainThread): Parsing macros/etc/datetime.sql
2022-07-28 00:32:12.862045 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-07-28 00:32:12.866958 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-07-28 00:32:12.877254 (MainThread): Parsing macros/schema_tests/unique.sql
2022-07-28 00:32:12.885765 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-07-28 00:32:12.895773 (MainThread): Parsing macros/relations.sql
2022-07-28 00:32:12.904275 (MainThread): Parsing macros/adapters.sql
2022-07-28 00:32:13.024957 (MainThread): Parsing macros/catalog.sql
2022-07-28 00:32:13.039806 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-07-28 00:32:13.131146 (MainThread): Partial parsing not enabled
2022-07-28 00:32:13.326965 (MainThread): Acquiring new postgres connection "model.dbt_.dim_types".
2022-07-28 00:32:13.327429 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:32:13.420366 (MainThread): Acquiring new postgres connection "model.dbt_.fct_summary".
2022-07-28 00:32:13.420803 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:32:13.447795 (MainThread): Acquiring new postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:32:13.448295 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:32:14.271731 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_.example

2022-07-28 00:32:15.414955 (MainThread): scipy not found, skipping conversion test.
2022-07-28 00:32:15.425105 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-07-28 00:32:15.426056 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 1 source
2022-07-28 00:32:15.436987 (MainThread): 
2022-07-28 00:32:15.438685 (MainThread): Acquiring new postgres connection "master".
2022-07-28 00:32:15.439111 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:32:15.557077 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_warehouse".
2022-07-28 00:32:15.557824 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-07-28 00:32:16.609463 (ThreadPoolExecutor-0_0): Using postgres connection "list_warehouse".
2022-07-28 00:32:16.612300 (ThreadPoolExecutor-0_0): On list_warehouse: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
2022-07-28 00:32:16.735234 (ThreadPoolExecutor-0_0): Got an error when attempting to open a postgres connection: 'could not connect to server: Connection refused
	Is the server running on host "localhost" (127.0.0.1) and accepting
	TCP/IP connections on port 5432?
could not connect to server: Cannot assign requested address
	Is the server running on host "localhost" (::1) and accepting
	TCP/IP connections on port 5432?
'
2022-07-28 00:32:16.740561 (ThreadPoolExecutor-0_0): Error running SQL: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
2022-07-28 00:32:16.741046 (ThreadPoolExecutor-0_0): Rolling back transaction.
2022-07-28 00:32:16.741367 (ThreadPoolExecutor-0_0): On list_warehouse: No close available on handle
2022-07-28 00:32:16.741804 (ThreadPoolExecutor-0_0): Error running SQL: macro list_schemas
2022-07-28 00:32:16.742084 (ThreadPoolExecutor-0_0): Rolling back transaction.
2022-07-28 00:32:16.747596 (MainThread): Connection 'master' was properly closed.
2022-07-28 00:32:16.749186 (MainThread): Connection 'list_warehouse' was properly closed.
2022-07-28 00:32:16.749678 (MainThread): ERROR: Database Error
  could not connect to server: Connection refused
  	Is the server running on host "localhost" (127.0.0.1) and accepting
  	TCP/IP connections on port 5432?
  could not connect to server: Cannot assign requested address
  	Is the server running on host "localhost" (::1) and accepting
  	TCP/IP connections on port 5432?
  
2022-07-28 00:32:16.752667 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d687631d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d68763990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d68763510>]}
2022-07-28 00:32:16.753418 (MainThread): Flushing usage events
2022-07-28 00:37:52.205092 (MainThread): Running with dbt=0.16.1
2022-07-28 00:37:52.655231 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/local/airflow/dbt_/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-07-28 00:37:52.702734 (MainThread): Tracking: tracking
2022-07-28 00:37:52.752627 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2ee0b4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2ee172550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2ee177f10>]}
2022-07-28 00:37:52.895856 (MainThread): Partial parsing not enabled
2022-07-28 00:37:52.927645 (MainThread): Parsing macros/core.sql
2022-07-28 00:37:52.948888 (MainThread): Parsing macros/materializations/helpers.sql
2022-07-28 00:37:52.991752 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-07-28 00:37:53.002290 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-07-28 00:37:53.151051 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-07-28 00:37:53.236308 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-07-28 00:37:53.265645 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-07-28 00:37:53.274887 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-07-28 00:37:53.371223 (MainThread): Parsing macros/materializations/common/merge.sql
2022-07-28 00:37:53.429718 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-07-28 00:37:53.461440 (MainThread): Parsing macros/materializations/view/view.sql
2022-07-28 00:37:53.517160 (MainThread): Parsing macros/materializations/table/table.sql
2022-07-28 00:37:53.549208 (MainThread): Parsing macros/adapters/common.sql
2022-07-28 00:37:53.731881 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-07-28 00:37:53.737205 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-07-28 00:37:53.746953 (MainThread): Parsing macros/etc/get_relation_comment.sql
2022-07-28 00:37:53.757737 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-07-28 00:37:53.762599 (MainThread): Parsing macros/etc/is_incremental.sql
2022-07-28 00:37:53.770843 (MainThread): Parsing macros/etc/query.sql
2022-07-28 00:37:53.776390 (MainThread): Parsing macros/etc/datetime.sql
2022-07-28 00:37:53.818348 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-07-28 00:37:53.823448 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-07-28 00:37:53.833155 (MainThread): Parsing macros/schema_tests/unique.sql
2022-07-28 00:37:53.838758 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-07-28 00:37:53.846775 (MainThread): Parsing macros/relations.sql
2022-07-28 00:37:53.854372 (MainThread): Parsing macros/adapters.sql
2022-07-28 00:37:53.976886 (MainThread): Parsing macros/catalog.sql
2022-07-28 00:37:53.994295 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-07-28 00:37:54.134882 (MainThread): Partial parsing not enabled
2022-07-28 00:37:54.321484 (MainThread): Acquiring new postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:54.322132 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:37:54.426389 (MainThread): Acquiring new postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:54.426990 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:37:54.454370 (MainThread): Acquiring new postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:37:54.454983 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:37:55.161614 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_.example

2022-07-28 00:37:56.276738 (MainThread): scipy not found, skipping conversion test.
2022-07-28 00:37:56.286898 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-07-28 00:37:56.289050 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 1 source
2022-07-28 00:37:56.298397 (MainThread): 
2022-07-28 00:37:56.299754 (MainThread): Acquiring new postgres connection "master".
2022-07-28 00:37:56.300394 (MainThread): Opening a new connection, currently in state init
2022-07-28 00:37:56.379593 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_warehouse".
2022-07-28 00:37:56.380778 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-07-28 00:37:56.918092 (ThreadPoolExecutor-0_0): Using postgres connection "list_warehouse".
2022-07-28 00:37:56.919010 (ThreadPoolExecutor-0_0): On list_warehouse: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
2022-07-28 00:37:56.950243 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2022-07-28 00:37:57.049150 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_warehouse_warehouse".
2022-07-28 00:37:57.050144 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_warehouse).
2022-07-28 00:37:57.060968 (ThreadPoolExecutor-1_0): Using postgres connection "list_warehouse_warehouse".
2022-07-28 00:37:57.061487 (ThreadPoolExecutor-1_0): On list_warehouse_warehouse: BEGIN
2022-07-28 00:37:57.063552 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.00 seconds
2022-07-28 00:37:57.064049 (ThreadPoolExecutor-1_0): Using postgres connection "list_warehouse_warehouse".
2022-07-28 00:37:57.064484 (ThreadPoolExecutor-1_0): On list_warehouse_warehouse: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "connection_name": "list_warehouse_warehouse"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
2022-07-28 00:37:57.155506 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.09 seconds
2022-07-28 00:37:57.179388 (ThreadPoolExecutor-1_0): On list_warehouse_warehouse: ROLLBACK
2022-07-28 00:37:57.268022 (MainThread): Using postgres connection "master".
2022-07-28 00:37:57.269542 (MainThread): On master: BEGIN
2022-07-28 00:37:57.281262 (MainThread): SQL status: BEGIN in 0.01 seconds
2022-07-28 00:37:57.281968 (MainThread): Using postgres connection "master".
2022-07-28 00:37:57.282422 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-07-28 00:37:57.909873 (MainThread): SQL status: SELECT 1 in 0.63 seconds
2022-07-28 00:37:57.920256 (MainThread): On master: ROLLBACK
2022-07-28 00:37:57.923132 (MainThread): Using postgres connection "master".
2022-07-28 00:37:57.923580 (MainThread): On master: BEGIN
2022-07-28 00:37:57.927050 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-07-28 00:37:57.928494 (MainThread): On master: COMMIT
2022-07-28 00:37:57.933782 (MainThread): Using postgres connection "master".
2022-07-28 00:37:57.934789 (MainThread): On master: COMMIT
2022-07-28 00:37:57.938088 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-07-28 00:37:57.939684 (MainThread): 00:37:57 | Concurrency: 1 threads (target='dev')
2022-07-28 00:37:57.946805 (MainThread): 00:37:57 | 
2022-07-28 00:37:58.000752 (Thread-1): Began running node model.dbt_.dim_types
2022-07-28 00:37:58.002309 (Thread-1): 00:37:57 | 1 of 3 START table model warehouse.dim_types......................... [RUN]
2022-07-28 00:37:58.003327 (Thread-1): Acquiring new postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.003701 (Thread-1): Re-using an available connection from the pool (formerly list_warehouse_warehouse).
2022-07-28 00:37:58.005027 (Thread-1): Compiling model.dbt_.dim_types
2022-07-28 00:37:58.105501 (Thread-1): Writing injected SQL for node "model.dbt_.dim_types"
2022-07-28 00:37:58.133863 (Thread-1): finished collecting timing info
2022-07-28 00:37:58.228089 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.228890 (Thread-1): On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
drop table if exists "warehouse"."warehouse"."dim_types__dbt_tmp" cascade
2022-07-28 00:37:58.253155 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-07-28 00:37:58.269169 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.269623 (Thread-1): On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
drop table if exists "warehouse"."warehouse"."dim_types__dbt_backup" cascade
2022-07-28 00:37:58.270666 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-07-28 00:37:58.335573 (Thread-1): Writing runtime SQL for node "model.dbt_.dim_types"
2022-07-28 00:37:58.337094 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.337489 (Thread-1): On model.dbt_.dim_types: BEGIN
2022-07-28 00:37:58.339093 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-07-28 00:37:58.339933 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.340644 (Thread-1): On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */


  create  table "warehouse"."warehouse"."dim_types__dbt_tmp"
  as (
    
with source_data as (
    select * from "source"
),

final as (
    SELECT distinct
    md5(types) as Id,
    types FROM source_data
)

select * from final
  );
2022-07-28 00:37:58.512950 (Thread-1): SQL status: SELECT 6 in 0.17 seconds
2022-07-28 00:37:58.528446 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.528896 (Thread-1): On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types" rename to "dim_types__dbt_backup"
2022-07-28 00:37:58.530331 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-07-28 00:37:58.540443 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.541144 (Thread-1): On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
alter table "warehouse"."warehouse"."dim_types__dbt_tmp" rename to "dim_types"
2022-07-28 00:37:58.542391 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-07-28 00:37:58.545546 (Thread-1): On model.dbt_.dim_types: COMMIT
2022-07-28 00:37:58.545986 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.546263 (Thread-1): On model.dbt_.dim_types: COMMIT
2022-07-28 00:37:58.586169 (Thread-1): SQL status: COMMIT in 0.04 seconds
2022-07-28 00:37:58.593840 (Thread-1): Using postgres connection "model.dbt_.dim_types".
2022-07-28 00:37:58.594339 (Thread-1): On model.dbt_.dim_types: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.dim_types"} */
drop table if exists "warehouse"."warehouse"."dim_types__dbt_backup" cascade
2022-07-28 00:37:58.862630 (Thread-1): SQL status: DROP TABLE in 0.27 seconds
2022-07-28 00:37:58.872968 (Thread-1): finished collecting timing info
2022-07-28 00:37:58.876703 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6194795f-5561-4cbc-bc08-e5233ecb8bdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2eb882c50>]}
2022-07-28 00:37:58.879176 (Thread-1): 00:37:58 | 1 of 3 OK created table model warehouse.dim_types.................... [SELECT 6 in 0.87s]
2022-07-28 00:37:58.882897 (Thread-1): Finished running node model.dbt_.dim_types
2022-07-28 00:37:58.885088 (Thread-1): Began running node model.dbt_.fct_summary
2022-07-28 00:37:58.885722 (Thread-1): 00:37:58 | 2 of 3 START table model warehouse.fct_summary....................... [RUN]
2022-07-28 00:37:58.887471 (Thread-1): Acquiring new postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:58.887908 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_.dim_types).
2022-07-28 00:37:58.888287 (Thread-1): Compiling model.dbt_.fct_summary
2022-07-28 00:37:58.917763 (Thread-1): Writing injected SQL for node "model.dbt_.fct_summary"
2022-07-28 00:37:58.918688 (Thread-1): finished collecting timing info
2022-07-28 00:37:58.950876 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:58.951360 (Thread-1): On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
drop table if exists "warehouse"."warehouse"."fct_summary__dbt_tmp" cascade
2022-07-28 00:37:58.952679 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-07-28 00:37:58.961467 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:58.961943 (Thread-1): On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
drop table if exists "warehouse"."warehouse"."fct_summary__dbt_backup" cascade
2022-07-28 00:37:58.963257 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-07-28 00:37:58.969047 (Thread-1): Writing runtime SQL for node "model.dbt_.fct_summary"
2022-07-28 00:37:58.970340 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:58.970756 (Thread-1): On model.dbt_.fct_summary: BEGIN
2022-07-28 00:37:58.971916 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-07-28 00:37:58.972572 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:58.972869 (Thread-1): On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */


  create  table "warehouse"."warehouse"."fct_summary__dbt_tmp"
  as (
    

with source_data as (
    select * from "source"
),

selection as (
    select track_id, md5(types) as type_id, traveled_d, avg_speed from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.traveled_d, sel.avg_speed
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
2022-07-28 00:37:59.637997 (Thread-1): SQL status: SELECT 922 in 0.66 seconds
2022-07-28 00:37:59.655610 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:59.656074 (Thread-1): On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
alter table "warehouse"."warehouse"."fct_summary" rename to "fct_summary__dbt_backup"
2022-07-28 00:37:59.657770 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-07-28 00:37:59.666831 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:59.667299 (Thread-1): On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
alter table "warehouse"."warehouse"."fct_summary__dbt_tmp" rename to "fct_summary"
2022-07-28 00:37:59.668654 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-07-28 00:37:59.671929 (Thread-1): On model.dbt_.fct_summary: COMMIT
2022-07-28 00:37:59.672470 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:59.672766 (Thread-1): On model.dbt_.fct_summary: COMMIT
2022-07-28 00:37:59.732429 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-07-28 00:37:59.739400 (Thread-1): Using postgres connection "model.dbt_.fct_summary".
2022-07-28 00:37:59.739846 (Thread-1): On model.dbt_.fct_summary: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_summary"} */
drop table if exists "warehouse"."warehouse"."fct_summary__dbt_backup" cascade
2022-07-28 00:37:59.839979 (Thread-1): SQL status: DROP TABLE in 0.10 seconds
2022-07-28 00:37:59.857515 (Thread-1): finished collecting timing info
2022-07-28 00:37:59.861673 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6194795f-5561-4cbc-bc08-e5233ecb8bdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2eb843d90>]}
2022-07-28 00:37:59.862560 (Thread-1): 00:37:59 | 2 of 3 OK created table model warehouse.fct_summary.................. [SELECT 922 in 0.97s]
2022-07-28 00:37:59.863026 (Thread-1): Finished running node model.dbt_.fct_summary
2022-07-28 00:37:59.863475 (Thread-1): Began running node model.dbt_.fct_trajectory
2022-07-28 00:37:59.867437 (Thread-1): 00:37:59 | 3 of 3 START table model warehouse.fct_trajectory.................... [RUN]
2022-07-28 00:37:59.868604 (Thread-1): Acquiring new postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:37:59.869000 (Thread-1): Re-using an available connection from the pool (formerly model.dbt_.fct_summary).
2022-07-28 00:37:59.870631 (Thread-1): Compiling model.dbt_.fct_trajectory
2022-07-28 00:37:59.949694 (Thread-1): Writing injected SQL for node "model.dbt_.fct_trajectory"
2022-07-28 00:37:59.950887 (Thread-1): finished collecting timing info
2022-07-28 00:38:00.016227 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:00.016875 (Thread-1): On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
drop table if exists "warehouse"."warehouse"."fct_trajectory__dbt_tmp" cascade
2022-07-28 00:38:00.018231 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-07-28 00:38:00.046213 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:00.046835 (Thread-1): On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
drop table if exists "warehouse"."warehouse"."fct_trajectory__dbt_backup" cascade
2022-07-28 00:38:00.049712 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-07-28 00:38:00.087138 (Thread-1): Writing runtime SQL for node "model.dbt_.fct_trajectory"
2022-07-28 00:38:00.089213 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:00.089674 (Thread-1): On model.dbt_.fct_trajectory: BEGIN
2022-07-28 00:38:00.090423 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-07-28 00:38:00.090854 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:00.091139 (Thread-1): On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */


  create  table "warehouse"."warehouse"."fct_trajectory__dbt_tmp"
  as (
    

with source_data as (
    select * from "source"
),

selection as (
    select track_id, md5(types) as type_id, trajectory from source_data
),

dim_types as (
    select * from "warehouse"."warehouse"."dim_types"
), 

final as (
    select sel.track_id, dim_types.types, sel.trajectory as paths
    from selection as sel 
    LEFT JOIN dim_types on sel.type_id = dim_types.Id
)

select * from final
  );
2022-07-28 00:38:32.091043 (Thread-1): SQL status: SELECT 922 in 32.00 seconds
2022-07-28 00:38:32.113927 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:32.114568 (Thread-1): On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
alter table "warehouse"."warehouse"."fct_trajectory" rename to "fct_trajectory__dbt_backup"
2022-07-28 00:38:32.116211 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-07-28 00:38:32.125976 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:32.126662 (Thread-1): On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
alter table "warehouse"."warehouse"."fct_trajectory__dbt_tmp" rename to "fct_trajectory"
2022-07-28 00:38:32.128436 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-07-28 00:38:32.132127 (Thread-1): On model.dbt_.fct_trajectory: COMMIT
2022-07-28 00:38:32.133009 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:32.133472 (Thread-1): On model.dbt_.fct_trajectory: COMMIT
2022-07-28 00:38:32.170898 (Thread-1): SQL status: COMMIT in 0.04 seconds
2022-07-28 00:38:32.193682 (Thread-1): Using postgres connection "model.dbt_.fct_trajectory".
2022-07-28 00:38:32.194143 (Thread-1): On model.dbt_.fct_trajectory: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "dbt_", "target_name": "dev", "node_id": "model.dbt_.fct_trajectory"} */
drop table if exists "warehouse"."warehouse"."fct_trajectory__dbt_backup" cascade
2022-07-28 00:38:32.217721 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-07-28 00:38:32.244294 (Thread-1): finished collecting timing info
2022-07-28 00:38:32.255718 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6194795f-5561-4cbc-bc08-e5233ecb8bdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2eb996790>]}
2022-07-28 00:38:32.256707 (Thread-1): 00:38:32 | 3 of 3 OK created table model warehouse.fct_trajectory............... [SELECT 922 in 32.38s]
2022-07-28 00:38:32.261237 (Thread-1): Finished running node model.dbt_.fct_trajectory
2022-07-28 00:38:32.323457 (MainThread): Using postgres connection "master".
2022-07-28 00:38:32.323961 (MainThread): On master: BEGIN
2022-07-28 00:38:32.328506 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-07-28 00:38:32.329048 (MainThread): On master: COMMIT
2022-07-28 00:38:32.329362 (MainThread): Using postgres connection "master".
2022-07-28 00:38:32.329629 (MainThread): On master: COMMIT
2022-07-28 00:38:32.332698 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-07-28 00:38:32.333984 (MainThread): 00:38:32 | 
2022-07-28 00:38:32.334976 (MainThread): 00:38:32 | Finished running 3 table models in 36.03s.
2022-07-28 00:38:32.335774 (MainThread): Connection 'master' was left open.
2022-07-28 00:38:32.340511 (MainThread): On master: Close
2022-07-28 00:38:32.341269 (MainThread): Connection 'model.dbt_.fct_trajectory' was left open.
2022-07-28 00:38:32.341696 (MainThread): On model.dbt_.fct_trajectory: Close
2022-07-28 00:38:32.450035 (MainThread): 
2022-07-28 00:38:32.453875 (MainThread): Completed successfully
2022-07-28 00:38:32.455693 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-07-28 00:38:32.462940 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2eba13e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2eb991490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2eb97f490>]}
2022-07-28 00:38:32.463732 (MainThread): Flushing usage events
